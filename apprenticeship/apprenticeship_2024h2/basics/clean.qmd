---
title: "Data Center Apprenticeship:\nR basics: Data wrangling with `dplyr`"
subtitle: "June 2024" 
date: "Last updated: `r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)
```

Data wrangling is the process of cleaning, structuring, and enriching raw data into a more usable format. The `dplyr` package is a part of the `tidyverse` and provides a set of functions that can be combined to perform the most common data wrangling tasks. The package is built around the concept of the "grammar of data manipulation", which is a consistent set of verbs that can be combined in many ways to achieve the desired result.

If `tidyverse` is not yet loaded in this R session, please do so now:

```{r}
library(tidyverse)
```

```{r, echo=FALSE}
student1 <- read_csv("data/student1.csv")
student2 <- read_tsv("data/student2.tab", skip = 1)
student3 <- readxl::read_excel("data/student3.xlsx", sheet = "Data")
student4 <- haven::read_spss("data/student4.sav")
student5 <- read_rds("data/student5.rds")
```

The main functions in `dplyr` are `filter()`, `select()`, `mutate()`, `arrange()`, `group_by()`, `summarize()`, and `rename()`. `dplyr` also provides a set of functions for combining datasets: `bind_rows()` and `bind_cols()` for row-wise and column-wise binding, and `left_join()`, `right_join()`, `inner_join()`, and `full_join()` for joining datasets based on common variables. These functions can be combined using the pipe operator `|>` (or `%>%`, they are mostly equivalent) to create a data wrangling workflow. The pipe operator takes the output of the function on its left and passes it as the first argument to the function on its right. This allows you to chain multiple functions together in a single line of code, making your code more readable and easier to understand.

In the following, we'll work with the `student` datasets imported in the previous section and show how to use the main `dplyr` functions to clean the data so it is suitable for analysis. These steps are useful even if the input data is quite clean, as we often need to work with only a subset of observations/variables, define new variables, or aggregate the data.

# Merging datasets

In our current application, we have five datasets that contain different observations of the same, larger dataset. So we can list all datasets in a row-binding function to combine them into a single dataset called `student`.

```{r}
student <- bind_rows(student1, student2, student3, student4, student5)
```

In the following, we'll demonstrate the key data cleaning functions on this merged tibble.

# Filtering observations

If we want to keep only a subset of observations, we can use the `filter()` function. We can specify a logical condition as the argument to `filter()`, and only observations that meet that condition will be kept. For example, to keep only students who are over 21 years old, we can use the following code:

```{r}
filter(student, Student_Age > 21)
```

In a pipe workflow, the same code would look like this:

```{r}
student |> 
  filter(Student_Age > 21)
```

We can also apply logical conditions to character variables, e.g. to keep only students who went to a private high school and who did not receive a failing grade. Filters can be combined with AND (`,` or `&`) and OR (`|`) operators into a single function. Note the use of quotation marks around the character values in the logical condition and the double equal sign `==` to denote equality.

```{r}
student |> 
  filter(High_School_Type == "Private", Grade != "Fail") 
```

Another useful logical operator is `%in%`, which allows you to filter observations based on a list of values. For example, to keep only students who receive either 75% or 100% scholarships, we can use the following code:

```{r}
student |> 
  filter(Scholarship %in% c("75%", "100%"))
```

# Selecting variables

If we want to keep only a subset of variables, we can use the `select()` function. We can specify the variables we want to keep (or exclude, with `-` signs) as the arguments to `select()`, and only those variables will be kept. For example, to keep only the `Id` and `Student_Age` variables, we can use the following code:

```{r}
select(student, Id, Student_Age)
```

We can also select columns based on their location in the dataframe or by looking for patterns in the column names:

```{r}
select(student, 1:3) # select the first three columns
select(student, starts_with("Student")) # select columns that start with "Student"
select(student, -Grade) # keep everything but "Grade"
select(student, -c(2, 6, 10)) # keep everything but the 2nd, 6th, and 10th columns
```

A pipe workflow allows us to combine the filtering and selecting operations into a single, step-by-step workflow:

```{r}
student |> 
  filter(Student_Age > 21) |> 
  select(Id, Student_Age)
```

# Creating new variables

If we want to create a new variable based on existing variables, we can use the `mutate()` function. We can specify the new variable name and the calculation for the new variable as the arguments to `mutate()`, and the new variable will be added to the dataset. For example, we can create a new variable `Daily_Study_Hours` that divides `Weekly_Study_Hours` by 5, a new variable `Class_Participation` that is a logical variable indicating whether the student has at least one "Yes" answer for reading, listening, and taking notes, and a new variable `Scholarship_num` that extracts the numeric value of `Scholarship` if the string contains a number.

```{r}
student |> 
  # create new variables
  mutate(Daily_Study_Hours = Weekly_Study_Hours / 5,
         Class_Participation = Reading == "Yes" | Listening_in_Class == "Yes" | Notes == "Yes",
         Scholarship_num =parse_number(Scholarship)) |> 
  # show only ID and the new variables
  select(Id, Daily_Study_Hours, Class_Participation, Scholarship_num)
```

# Sorting the data

If we want to sort the data based on one or more variables, we can use the `arrange()` function, taking the tibble and a variable list as its arguments. By default, `arrange()` sorts in ascending order, but you can specify descending order by using the `desc()` function. For example, to sort the data by `Student_Age` in descending order, and `Weekly_Study_Hours` in ascending order, we can use the following code:

```{r}
student |> 
  arrange(desc(Student_Age), Weekly_Study_Hours)
```

# Renaming variables

If we want to rename variables, we can use the `rename()` function with the argument structure `new name = old name`. For example, we can rename the `Student_Age` variable to `age` and the `Weekly_Study_Hours` variable to `weekly_hours`, we can use the following code:

```{r}
student |> 
  rename(age = Student_Age, weekly_hours = Weekly_Study_Hours)
```

# Categorical variables as factors

It is often useful to clearly define the levels of a categorical variable, especially if these levels have a meaningful ordering. For unordered categories, R provides the data type `factor`, while for ordered variables the relevant data type is `ordered`. Factor and ordered values appear as character strings when viewed, but are treated as numbers with labels internally, which makes it easier to show descriptives of the variable and include it in models. For example, we can define `High_School_Type` as a factor with three levels and `Attendance` as ordered with the `factor()` and `ordered()` functions. If we don't specify the levels of the factor explicitly, then the levels will be sorted alphabetically.

```{r}
student |> 
  mutate(High_School_Type = factor(High_School_Type),
         Attendance = ordered(Attendance, levels = c("Never", "Sometimes", "Always"))) |> 
  select(High_School_Type, Attendance) |> 
  # view variable types and levels by looking at the structure of the data
  str()
```

# Data cleaning as a single pipeline

Until now we didn't save any of our data wrangling steps as new objects, so the original `student1` object is still unchanged. If we want to save the cleaned data as a new object, we can assign the result of the pipe workflow to a new object.

```{r}
student_subset <- student1 |> 
  filter(Student_Age > 21) |> 
  select(Id, Student_Age) |> 
  arrange(desc(Student_Age)) |> 
  rename(age = Student_Age)
```

To prepare for the rest of the analysis, let's create a new `data` object that keeps all observations, and converts some of the indicators to numeric and logical, and rename the relevant variables to convenient "snake case":

```{r}
data <- student |> 
  mutate(scholarship = parse_number(Scholarship),
         sex = factor(Sex),
         # ifelse contains a logical condition, a value if TRUE, and a value if FALSE
         additional_work = ifelse(Additional_Work == "Yes", TRUE, FALSE),
         reading = ifelse(Reading == "Yes", TRUE, FALSE),
         notes = ifelse(Notes == "Yes", TRUE, FALSE),
         listening = ifelse(Listening_in_Class == "Yes", TRUE, FALSE),
         # case_when is an expansion of ifelse: it allows multiple conditions
         # the value after the tilde (~) is the value if the condition is TRUE
         grade = case_when(
           Grade == "Fail" ~ 0,
           Grade == "DD" ~ 1,
           Grade == "DC" ~ 1.5,
           Grade == "CC" ~ 2,
           Grade == "CB" ~ 3,
           Grade == "BB" ~ 3,
           Grade == "BA" ~ 4,
           Grade == "AA" ~ 4
         )) |> 
  rename(id = Id, age = Student_Age) |> 
  select(id, age, sex, scholarship, additional_work, reading, notes, listening, grade)
```

```{r, echo=FALSE}
write_csv(data, "data/data.csv")
```

# Go to

-   [Introduction to R](../intro)
-   [Finding and importing data](../import)
-   [Summary statistics](../summary)
-   [Data visualization with `ggplot2`](../ggplot)
-   [Hypothesis testing / modelling](../tests)

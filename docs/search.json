[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the UCR Data Center!",
    "section": "",
    "text": "Learn more about the Data Center, or check out our general and course-specific resources for improving your data science skills.\nIf you’re looking for data science support with a UCR course or your SEPR, or you’re interested in doing an internship with the Data Center, please email us or attend our office hours."
  },
  {
    "objectID": "tutorials_old.html",
    "href": "tutorials_old.html",
    "title": "Tutorials",
    "section": "",
    "text": "Setting up R\nStart here if you have never used R before.\n\nInstalling R\nGetting started with R and RStudio\nObjects and functions\n\n\n\nIntroduction to R\nIf you can find your way around R and RStudio, but want to learn more about the basics. Most of these tutorials can be used independently of each other. Any prerequisites are mentioned in the introduction of each tutorial.\n\nImporting data\nData wrangling: filtering rows and selecting columns\nData wrangling: creating new variables\nData wrangling: summarizing data (within groups)\nPivoting: data in wide and long format\nThe tidy workflow\nData visualization: introduction to ggplot2\nData visualization: distributions\nData visualization: relationships between variables\nData visualization: patterns over time\n\n\n\nR topics for beginners\nIf you’re familiar with basic data cleaning and visualization, but want to learn more about specific topics that are relevant to your disciplinary background or interests. The tutorials in this section can be used independently of each other.\n\nWorking with spatial data\nWorking with text\nStatistics in R\n\n\n\nAdvanced R topics\nIf you have more experience with R (e.g. ENGDATA101) and want to learn more. These tutorials are particularly useful for students in the Data Center Apprenticeship program.\n\nMore on importing data\nMore on data visualization\nText analysis with regular expressions\nWeb and pdf scraping\nInteractive applications with Shiny\nWriting your own functions\nAdvanced data types and functionals\nNeuroimaging in R\n\n\n\nReproducible research workflows\nIf you want to learn more about how to make your workflows more reproducible and efficient.\n\nVersion control with GitHub\nCollaborating on GitHub\nCompile documents with RMarkdown/Quarto\nWrite papers in LaTeX (with Overleaf)\n\n\n\nOther\n\nUseful data sources\nAdditional materials"
  },
  {
    "objectID": "tutorials/r_text.html",
    "href": "tutorials/r_text.html",
    "title": "Working with text",
    "section": "",
    "text": "This tutorial introduces how to treat text as data in R using the tidytext package. It introduces methods of importing text, tokenizing text, looking for (partial) matches with simple regular expressions, and analyzing word frequencies.\nWe start by installing and loading the tidytext package, and loading the tidyverse package.\n\n# install.packages(\"tidytext\")\nlibrary(tidytext)\nlibrary(tidyverse)"
  },
  {
    "objectID": "tutorials/r_text.html#counting-word-frequencies",
    "href": "tutorials/r_text.html#counting-word-frequencies",
    "title": "Working with text",
    "section": "Counting word frequencies",
    "text": "Counting word frequencies\nThe simplest method of getting a quick overview of a long text is to count the number of times each word appears in the text, and looking at what the most frequent words are. We can get these word frequencies using the count() function, specifying which variable we want to count.\n\nclean_text |&gt; \n  count(word)\n\n# A tibble: 60 × 2\n   word         n\n   &lt;chr&gt;    &lt;int&gt;\n 1 academic     1\n 2 aiding       1\n 3 analysis     1\n 4 analyze      1\n 5 and          5\n 6 by           1\n 7 can          2\n 8 content      1\n 9 customer     1\n10 data         1\n# ℹ 50 more rows\n\n\nThe count() function has an argument sort, which allows us to sort the output from most frequent to least frequent words.\n\nclean_text |&gt; \n  count(word, sort = TRUE)\n\n# A tibble: 60 × 2\n   word          n\n   &lt;chr&gt;     &lt;int&gt;\n 1 and           5\n 2 can           2\n 3 sentiment     2\n 4 trends        2\n 5 academic      1\n 6 aiding        1\n 7 analysis      1\n 8 analyze       1\n 9 by            1\n10 content       1\n# ℹ 50 more rows"
  },
  {
    "objectID": "tutorials/r_text.html#looking-for-exact-and-partial-word-matches",
    "href": "tutorials/r_text.html#looking-for-exact-and-partial-word-matches",
    "title": "Working with text",
    "section": "Looking for exact and partial word matches",
    "text": "Looking for exact and partial word matches\nIn many cases we are interested only in analyzing parts of a text that contain our topic of interest. For example, we may want to find which parts of a text talk about “data” and in what context. In that case, we can use the filter() function to keep only observations that meet a particular criteria. You can see some more explanation and general examples of the filter() function in this tutorial.\nWhen we are working with words, exact matches are often enough for our purposes. For example, we can look at how many rows in our clean_text tibble have “data” as the value of the word variable.\n\nclean_text |&gt; \n  filter(word == \"data\")\n\n# A tibble: 1 × 1\n  word \n  &lt;chr&gt;\n1 data \n\n\nHowever, this filter tells us nothing about the context in which “data” appears. For that, it would be better to split the text into sentences, and find which sentence contains the word “data”. But if we tokenize the text into sentences, an exact match won’t find the sentence we’re looking for.\n\n# split the text into sentences\nsentences &lt;- raw_text |&gt; \n  as_tibble() |&gt; \n  unnest_tokens(output = sentence, input = value, token = \"sentences\")\n\n# keep only rows with an exact match to \"data\" (no such rows)\nsentences |&gt; \n  filter(sentence == \"data\")\n\n# A tibble: 0 × 1\n# ℹ 1 variable: sentence &lt;chr&gt;\n\n\nIf we want to find a partial string match (i.e. a sentence that among other content contains the word “data”), we need to use a special function to detect partial matches. This function is called str_detect() and takes the arguments of the variable that contains the elements you want to evaluate and the pattern you’re looking for. In our case, this variable is sentence and the pattern is data. str_detect() returns a logical vector, i.e. for each element of your variable it tells you whether it matches the pattern (TRUE) or not (FALSE).\n\n# example of str_detect()\nstr_detect(string = c(\"A\", \"AB\", \"BB\"), pattern = \"A\")\n\n[1]  TRUE  TRUE FALSE\n\n# look for partial match to \"data\" (one sentence)\nsentences |&gt; \n  filter(str_detect(string = sentence, pattern = \"data\"))\n\n# A tibble: 1 × 1\n  sentence                                                                      \n  &lt;chr&gt;                                                                         \n1 text analysis in r provides valuable insights by uncovering patterns, trends,…"
  },
  {
    "objectID": "tutorials/r_spatial.html",
    "href": "tutorials/r_spatial.html",
    "title": "Working with spatial data",
    "section": "",
    "text": "This tutorial is not ready yet. Please come back later."
  },
  {
    "objectID": "tutorials/r_scraping.html",
    "href": "tutorials/r_scraping.html",
    "title": "Web and pdf scraping",
    "section": "",
    "text": "This tutorial covers how to scrape data from webpages and PDF documents using the rvest and pdftools packages in R. The introduction to the HTML is a slightly modified version of the Web Scraping with RVest tutorial by Kasper Welbers, Wouter van Atteveldt & Philipp Masur."
  },
  {
    "objectID": "tutorials/r_scraping.html#html-basics",
    "href": "tutorials/r_scraping.html#html-basics",
    "title": "Web and pdf scraping",
    "section": "HTML basics",
    "text": "HTML basics\nThe vast majority of the internet uses HTML to make nice looking web pages. Simply put, HTML is a markup language that tells a browser what things are shown where. For example, it could say that halfway on the page there is a table, and then tell what data there is in the rows and columns. In other words, HTML translates data into a webpage that is easily readable by humans. With web scraping, we’re basically translating the page back into data.\nTo get a feel for HTML code, open this link here in your web browser. Use Chrome or Firefox if you have it (not all browsers let you inspect elements as we’ll do below). You should see a nicely formatted document. Sure, it’s not very pretty, but it does have a big bold title, and two tables.\nThe purpose of this page is to show an easy example of what the HTML code looks like. If you right-click on the page, you should see an option like view page source. If you select it you’ll see the entire HTML source code. This can seem a bit overwhelming, but don’t worry, you will never actually be reading the entire thing. We only need to look for the elements that we’re interested in, and there are some nice tricks for this. For now, let’s say that we’re interested in the table on the left of the page. Somewhere in the middle of the code you’ll find the code for this table.\n&lt;table class=\"someTable\" id=\"exampleTable\"&gt;           &lt;!-- table                --&gt;\n    &lt;tr class=\"headerRow\"&gt;                            &lt;!--    table row         --&gt;\n        &lt;th&gt;First column&lt;/th&gt;                         &lt;!--       table header   --&gt;\n        &lt;th&gt;Second column&lt;/th&gt;                        &lt;!--       table header   --&gt;\n        &lt;th&gt;Third column&lt;/th&gt;                         &lt;!--       table header   --&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;                                              &lt;!--    table row         --&gt;\n        &lt;td&gt;1&lt;/td&gt;                                    &lt;!--       table data     --&gt;\n        &lt;td&gt;2&lt;/td&gt;                                    &lt;!--       table data     --&gt;\n        &lt;td&gt;3&lt;/td&gt;                                    &lt;!--       table data     --&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;                                              &lt;!--    table row         --&gt;\n        &lt;td&gt;4&lt;/td&gt;                                    &lt;!--       table dat      --&gt;\n        &lt;td&gt;5&lt;/td&gt;                                    &lt;!--       table dat      --&gt;\n        &lt;td&gt;6&lt;/td&gt;                                    &lt;!--       table data     --&gt;\n    &lt;/tr&gt;\n&lt;/table&gt;\nThis is the HTML representation of the table, and it’s a good showcase of what HTML is about. The parts after the &lt;!-- are comments and therefore do not affect the layout of the website. First of all, notice that the table has a tree-like shape. At the highest level we have the &lt;table&gt;. This table has three table rows (&lt;tr&gt;), which we can think of as it’s children. Each of these rows in turn also has three children that contain the data in these rows.\nLet’s see how we can tell where the table starts and ends. The table starts at the opening tag &lt;table&gt;, and ends at the closing tag &lt;/table&gt; (the / always indicates a closing tag). This means that everything in between of these tags is part of the table. Likewise, we see that each table row opens with &lt;tr&gt;, and closes with &lt;/tr&gt;, and everything between these tags is part of the row. In the first row, these are 3 table headers &lt;th&gt;, which contain the column names. The second and third row each have 3 table data &lt;td&gt;, that contain the data points.\nEach of these components can be thought of as an element. It’s these elements that we want to extract into R objects with rvest.\nSo let’s use this simple example site to go over the main rvest functions."
  },
  {
    "objectID": "tutorials/r_scraping.html#simple-example-with-rvest",
    "href": "tutorials/r_scraping.html#simple-example-with-rvest",
    "title": "Web and pdf scraping",
    "section": "Simple example with rvest",
    "text": "Simple example with rvest\nFirst load the rvest and tidyverse packages, and specify the URL of the webpage we intend to scrape. You can define the URL within as a separate object or inside the scraping function; since often you want to scrape multiple pages in one workflow, it is good practice to specify URLs outside the function.\n\nlibrary(tidyverse)\nlibrary(rvest)\n\nurl &lt;- \"https://bit.ly/3lz6ZRe\"\n\nThe function to read the HTML code from a URL into R is read_html(), with the URL as the function argument.\n\nhtml &lt;- read_html(url)\n\nThe result of this function is a list containing the raw HTML code, which is quite difficult to work with. So the next step is to extract the elements that we want to work with.\nElements can be selected with the html_element() or html_elements() function depending on whether you want to access only the first item matching the element specification or get a list of all fitting elements.\nBy element specification we usually refer to CSS selectors that categorize the object we want to extract. CSS is mostly used by web developers to style web pages, but the CSS selectors are also a good way to identify types of data such as tables or lists. Once we have the CSS selector we are looking for, we can add it as the argument of the html_elements() function, and extract only the parts of the HTML code that correspond to the selector.\nThere are quite a lot of CSS selectors, and the table below gives some of the main examples. However, you don’t actually need to remember any of these, but instead you can use selector tools to extract the information you need.\n\n\n\n\n\n\n\n\nselector\nexample\nSelects\n\n\n\n\nelement/tag\ntable\nall &lt;table&gt; elements\n\n\nclass\n.someTable\nall elements with class=\"someTable\"\n\n\nid\n#steve\nunique element with id=\"steve\"\n\n\nelement.class\ntr.headerRow\nall &lt;tr&gt; elements with the headerRow class\n\n\nclass1.class2\n.someTable.blue\nall elements with the someTable AND blue class\n\n\n\nInstead of going through the raw HTML and trying to match up the code to the observed website, you can use a browser extension that tells you the CSS selector you’re looking for just by clicking on the part of the webpage that you’d like to select. In Chrome this extension is called Selector Gadget. You can simply search for the extension and install it, at which point you can use it on your chosen webpage by clicking on the extension in your list of installed browser extensions.\nIn the example webpage you can see that selecting the title gives you a CSS selector “h2” (which stands for level 2 header), while selecting any of the main text gives “p” for paragraph. Selecting elements can sometimes get a bit difficult with the gadget, and you can’t always get it to do exactly what you want: for example, it is hard to select the entire table and receive the selector “table”, as the gadget often tries to select subitems of the table such as “td” instead. If you can’t get the gadget to select what you’re looking for, it might be a good idea to go back to manually inspecting the HTML source code and looking for the element there.\nIf the selector gadget fails, the Inspect option of Chrome may be more helpful than viewing the full source code. Inspecting the page allows you to focus on particular elements, because when you hover your mouse over the elements, you can directly see the correspondence between the code and the page. The tree structure is also made more obvious by allowing you to fold and unfold elements by clicking on the triangles on the left. Therefore you can quickly identify the HTML elements that you want to select.\nIn this example let’s try to extract the table with the ID “#exampleTable”. Alternatively, we can extract both tables by asking for all “table” elements.\n\n# Select the element with ID \"exampleTable\"\nexample_table &lt;- html |&gt;\n  html_element(\"#exampleTable\")\n\nThe output looks a bit messy, but what it tells us is that we have selected the &lt;table&gt; html element/node. It also shows that this element has the three table rows (tr) as children, and shows the values within these rows.\nIn order to turn the HTML code of the table into a tibble, we can use the html_table() function.\n\nexample_table_tidy &lt;- example_table |&gt;\n  html_table()\n\nPutting the whole workflow together, web scraping takes three main steps:\n\nload the full HTML code with read_html()\nextract the elements you need with html_elements()\ntransform the HTML code to clean objects with e.g. html_table() or html_text()\n\nTo get both tables into a list of tibbles, we can use the following code chunk:\n\ntables &lt;- read_html(url) |&gt;\n  html_elements(\"table\") |&gt;\n  html_table()\n\nOf course, in this case we worked with a very small and clean example, so the tables list already contains clean tibbles. That is not always the case, and often you need further data wrangling steps to clean up variable names, data types, row structure, ect., but at that point you can use standard tidyverse workflows.\nAs another example, you can extract and display the text from the right column of the example page:\n\nread_html(url) |&gt;\n  html_elements(\"div.rightColumn\") |&gt;\n  html_text2() |&gt;\n  cat()\n\nRight Column\n\nHere's another column! The main purpose of this column is just to show that you can use CSS selectors to get all elements in a specific column.\n\nnumbers letters \n1   A   \n2   B   \n3   C   \n4   D   \n5   E   \n6   F   \n\n\nWe used the html_text2() function to transform HTML code into plain text (html_text2() usually creates nicer text output than html_text()), and then used the cat() function to print it on the screen.\nAnother nice function is html_attr() or html_attrs(), for getting attributes of elements. With html_attrs we get all attributes. For example, we can get the attributes of the #exampleTable.\n\nhtml |&gt;\n  html_elements(\"#exampleTable\") |&gt;\n  html_attrs()\n\n[[1]]\n         class             id \n   \"someTable\" \"exampleTable\" \n\n\nBeing able to access attributes is especially useful for scraping links. Links are typically represented by &lt;a&gt; tags, in which the link is stored as the href attribute.\n\nhtml |&gt;\n  html_elements(\"a\") |&gt;\n  html_attr(\"href\")\n\n[1] \"https://blog.hubspot.com/website/how-to-inspect\""
  },
  {
    "objectID": "tutorials/r_scraping.html#scrape-the-fact-sheet-of-a-single-college",
    "href": "tutorials/r_scraping.html#scrape-the-fact-sheet-of-a-single-college",
    "title": "Web and pdf scraping",
    "section": "Scrape the fact sheet of a single college",
    "text": "Scrape the fact sheet of a single college\nLet’s start by writing a scraping script for one college as a representative example. In this case, let’s use Amherst College, and try to extract the colors “white” and “purple” from the grey factsheet on the right hand side of the page.\nThe selector gadget shows us that we can extract the elements by referring to “.infobox”. Instead of extracting the infobox as a table, let’s extract the variable labels and values separately into two character vectors, and combine them into a tibble afterwards. We can do this by extracting “.infobox-label” and “.infobox-data” elements separately, and converting them into character strings with htlm_text2(). In this case this is a better approach than extracting the whole table, because it gives us more control over the layout of the tibble, which makes it easier to handle slight differences in the different Wikipedia pages. You can also try to extract the whole “.infobox” as a table, but you might need to take some additional steps of data wrangling e.g. to fix variable names.\n\nurl &lt;- \"https://en.wikipedia.org/wiki/Amherst_College\"\nhtml &lt;- read_html(url)\n\nlabel &lt;- html |&gt;\n  html_elements(\".infobox-label\") |&gt;\n  html_text2()\n\nvalue &lt;- html |&gt;\n  html_elements(\".infobox-data\") |&gt;\n  html_text2()\n\nfactsheet &lt;- tibble(label, value)\nfactsheet\n\n# A tibble: 29 × 2\n   label                 value                                                  \n   &lt;chr&gt;                 &lt;chr&gt;                                                  \n 1 Motto                 \"Terras Irradient (Latin)\"                             \n 2 Motto in English      \"Let them enlighten the lands[1]\"                      \n 3 Type                  \"Private liberal arts college\"                         \n 4 Established           \"1821; 204 years ago (1821)\"                           \n 5 Accreditation         \"NECHE\"                                                \n 6 Academic affiliations \".mw-parser-output .hlist dl,.mw-parser-output .hlist …\n 7 Endowment             \"$3.55 billion (2024)[2]\"                              \n 8 President             \"Michael A. Elliott\"                                   \n 9 Academic staff        \"338 (fall 2024)[3]\"                                   \n10 Undergraduates        \"1,914 (fall 2024)[3]\"                                 \n# ℹ 19 more rows"
  },
  {
    "objectID": "tutorials/r_scraping.html#find-and-clean-the-school-color-values",
    "href": "tutorials/r_scraping.html#find-and-clean-the-school-color-values",
    "title": "Web and pdf scraping",
    "section": "Find and clean the school color values",
    "text": "Find and clean the school color values\nThe resulting factsheet tibble indeed contains the school colors, but also a lot of other information that we don’t need. In addition, the cell containing the colors also has some HTML code that wasn’t removed by the previous code. We might also want to make the color names more consistent so we can count the number of occurrences more easily (so e.g. we don’t have “Red” and “red” separately).\nOne idea for making the color references more consistent is to allow only the colors that R recognizes. While this is not the only approach and it will lead to a loss of information if a college uses a particular shade not defined in R, this approach has a nice advantage: when we visualize the distribution of colors, we can actually use the color codes defined in R to add color to our figure. So let’s extract the vector colors defined in R with the colors() function, and convert this vector to a single string with the colors separated by |. Recall from the workshop on regular expressions that | in a regex stands for “OR”, so using the resulting r_colors string as a pattern will detect any occurrence of an R color in a string.\n\nr_colors &lt;- colors() |&gt; paste(collapse = \"|\")\n\nNow we can move on to wrangling our factsheet tibble: let’s keep only the row containing the color, and use string operations to extract the colors appearing in the value variable.\nBy looking at the Wikipedia page, you might figure out that the weird “.mw-parser-output…” section of the value string refers to the displayed color squares. If that part didn’t contain any color references, there would be no problem with leaving it in the value, but notice that it specifies that the square border should be black. So if we extract all colors appearing in the text, we’ll mistakenly find that one of the school colors is black. So let’s remove the text creating these squares: it seems that it starts with “.mw-parser-output” and ends with “.mw-parser-output .legend-text{}” (normally you’d need to check the results from multiple different college pages to make sure that this pattern is consistent).\nOnce only the color (and some footnote references) remain in the cell, we can extract the colors recognized by R using str_extract_all(). Note the use of str_extract_all() over str_extract() to make sure that we extract all colors if a school has more than one colors.\nThe result of str_extract_all() is a variable of character vector instead of single strings, which makes the variable quite hard to work with. It would be better to have a row corresponding to every individual color a school has – so we’d have two rows for Amherst, one with purple and one with white. Then we can easily count how many universities use a particular color. We can do this transformation by calling the unnest() function, which expands the character vector to become separate observations corresponding to each element of the vector.\n\nfactsheet |&gt;\n  filter(label == \"Colors\") |&gt;\n  mutate(value = str_remove(value, \"\\\\.mw-parser-output.*\\\\.mw-parser-output \\\\.legend-text\\\\{\\\\}\"),\n         known_color = str_extract_all(tolower(value), r_colors)) |&gt;\n  unnest()\n\n# A tibble: 2 × 3\n  label  value                known_color\n  &lt;chr&gt;  &lt;chr&gt;                &lt;chr&gt;      \n1 Colors \" Purple & white[4]\" purple     \n2 Colors \" Purple & white[4]\" white"
  },
  {
    "objectID": "tutorials/r_scraping.html#get-a-list-of-colleges-with-wikipedia-links",
    "href": "tutorials/r_scraping.html#get-a-list-of-colleges-with-wikipedia-links",
    "title": "Web and pdf scraping",
    "section": "Get a list of colleges with Wikipedia links",
    "text": "Get a list of colleges with Wikipedia links\nNow that we have a scraper that should work for any LAS college Wikipedia page with the same structure as Amherst, we need a list of the URLs that we want to scrape. Conveniently, there is a Wikipedia page of a list of LAS colleges, which features a list linking to all individual college Wikipedia pages. So all we have to do is scrape that list and extract the URLs.\nThe selector gadget shows us that we can extract the list of schools with the element tag “#mw-content-text li a” – that is, we’re looking for elements of the content text that are both a list (“li”) and a hyperlink (“a”). Then we can extract the attributes of the hyperlink to get the URL from “href” and the school name from “title”, and combine the resulting vectors to a tibble.\nSince there are a few links that have the same element tag as the school links, but are not school links, we can filter the resulting list of links by requiring that the link name includes “University” or “College” – a quick look at the Wikipedia list shows that all schools meet this criteria. In addition, looking at the URLs, you might notice that they are relative links that only contain the subpage of Wikipedia. In order to open the URL with rvest, we need to complete URL, so we should add “https://en.wikipedia.org” to the start of each link – the paste0() function does exactly that (it combines its arguments into a single string, with no separator between them). The resulting list object is a tibble with two columns: the name of all colleges and their corresponding Wikipedia page URL.\n\nurl &lt;- \"https://en.wikipedia.org/wiki/List_of_liberal_arts_colleges_in_the_United_States\"\n\nhtml &lt;- read_html(url) |&gt;\n  html_elements(\"#mw-content-text li a\")\n\nlist &lt;- tibble(url = html_attr(html, \"href\"),\n               name = html_attr(html, \"title\")) |&gt;\n  filter(str_detect(name, \"(University|College)\")) |&gt;\n  mutate(url = paste0(\"https://en.wikipedia.org\", url))"
  },
  {
    "objectID": "tutorials/r_scraping.html#write-a-function-for-extracting-the-color-given-a-link",
    "href": "tutorials/r_scraping.html#write-a-function-for-extracting-the-color-given-a-link",
    "title": "Web and pdf scraping",
    "section": "Write a function for extracting the color given a link",
    "text": "Write a function for extracting the color given a link\nWe will cover writing functions in more detail later in the apprenticeship, but for now let’s have a look at the example below. You might notice that the code inside the same code we have seen before: we extract the HTML code from a URL input, get the vector of infobox labels and data, and combine them into a tibble, keeping only the URL and the cell containing the color (notice that the url vector has a length of one and therefore gets recycled in the tibble). By containing this code within a function(){} argument, we make the code reusable: we can rerun it just by calling the function name (in this case, get_school_color) and the arguments we would like to use as inputs. In the function definition these arguments are listed inside the parentheses: in this case, the only argument is url so by calling the get_school_color() function with a different url argument will run the code in the function body (inside the curly braces), changing every mention of url into the the new URL specified in the function argument.\nThe example below shows how to use this new function to extract the school colors of Amherst. Notice that if you run the function without assigning the result to a new object, it prints the final tibble created by the code in the function body. This happens because in the function we don’t assign this final tibble to an object, therefore by default it becomes the value returned by the function. In turn, if we assign the outcome of the function to an object, then the resulting tibble of colors gets saved to the R environment (notice that our function behaves in the same way as pre-defined functions like sum() – printing the result if the function is called, and saving it to the environment if assigned to an object).\n\nget_school_color &lt;- function(url) {\n  html &lt;- read_html(url)\n\n  label &lt;- html |&gt;\n    html_elements(\".infobox-label\") |&gt;\n    html_text2()\n\n  value &lt;- html |&gt;\n    html_elements(\".infobox-data\") |&gt;\n    html_text2()\n\n  tibble(url, label, value) |&gt;\n    filter(label == \"Colors\") |&gt;\n    select(-label)\n}\n\nget_school_color(\"https://en.wikipedia.org/wiki/Amherst_College\")\n\n# A tibble: 1 × 2\n  url                                           value                           \n  &lt;chr&gt;                                         &lt;chr&gt;                           \n1 https://en.wikipedia.org/wiki/Amherst_College .mw-parser-output .legend{page-…\n\namherst_color &lt;- get_school_color(\"https://en.wikipedia.org/wiki/Amherst_College\")"
  },
  {
    "objectID": "tutorials/r_scraping.html#get-all-school-colors-and-visualize-the-distribution",
    "href": "tutorials/r_scraping.html#get-all-school-colors-and-visualize-the-distribution",
    "title": "Web and pdf scraping",
    "section": "Get all school colors and visualize the distribution",
    "text": "Get all school colors and visualize the distribution\nSo the next thing to do is to run the function we just defined for all URLs that we have in our list object. Again, we will cover appropriate functions for these repeated actions later, for now we’ll just learn how to solve this particular challenge.\nIf you are familiar with other programming languages, you might consider using a loop to run the function for every element of the url variable of the list tibble. In R, however, loops are not the best solution in many cases. Instead, the tidyverse contains a package called purrr that contains functions that takes vectors and functions as its inputs: it runs the function one by one with each element of the vector as the function argument, and combines the results into a single object. In this case, we can use the map_df() function to combine the results into a dataframe (the map() function uses a list instead), and we can take the vector of list$url as the potential arguments for the get_school_color function. Since this single line of code opens and scrapes hundreds of webpages, it can take a few minutes to run.\n\ndata &lt;- map_df(list$url, get_school_color)\n\nOnce we have our data object that contains all the color information extracted from the webpages, we can take some additional steps of data cleaning in order to visualize the distribution of colors. We can simply repeat the same steps that worked for the case of a single college.\nFirst we create a string that defines all colors known to R, separated by | to use as a regex pattern. Then we can take the data object, and remove the HTML code creating the color squares, and use the regex pattern to extract the colors recognized by R. The extra line in the mutate function converts all occurrences of the color “navy blue” to “navy” because otherwise R will extract “navy” and “blue” separately and therefore inflate the occurrences of “blue” – you’ll notice issues like this after you try to extract the colors and have a look at the results. We again use the unnest() function to have a new row for every element of the character vector of known colors. In addition, we merge the results with the original list object so we can add the university names as identifiers in addition to the URL, and keep only the name and known_color variables, and only unique combinations of these values. At this point you might also notice that grey and gray are both accepted spellings of the same color, so we can replace one with the other to make sure the spelling is consistent across colleges.\nOnce we have this colors tibble that contains the extracted colors for each college, it is quite easy to count the number of times each color appears and plot the results on a bar chart. The fct_reorder() function in the aesthetic specification arranges the values based on the corresponding counts. As for the bars, instead of specifying the fill as an aesthetic or a single value, we specify it as a character vector that has the same length as the number of categories plotted. In this case we can exploit the fact that the known_color variable already contains color strings recognized by R, so by specifying the variable as the colors we want to use, each bar will be filled with the color corresponding to the category displayed.\n\nr_colors &lt;- colors() |&gt; paste(collapse = \"|\")\n\ncolors &lt;- data |&gt;\n  mutate(value = str_remove(value, \"\\\\.mw-parser-output.*\\\\.mw-parser-output \\\\.legend-text\\\\{\\\\}\"),\n         value = str_replace(value, \"[nN]avy [bB]lue\", \"navy\"),\n         known_color = str_extract_all(tolower(value), r_colors)) |&gt;\n  unnest(known_color) |&gt;\n  left_join(list) |&gt;\n  distinct(name, known_color) |&gt;\n  mutate(known_color = ifelse(known_color == \"gray\", \"grey\", known_color))\n\ncolor_counts &lt;- colors |&gt;\n  count(known_color)\n\nggplot(color_counts, aes(n, fct_reorder(known_color, n))) +\n  geom_col(fill = color_counts$known_color, color = \"black\") +\n  xlab(\"Number of colleges with school color\") + ylab(NULL) +\n  theme_light()\n\n\nThe resulting plot shows how often each color is used as the school colors of a US liberal arts college. The results are not perfect, as not all hues are recognized and therefore extracted by R: for instance, “cardinal” (a shade of red) is used by 14 colleges, but the color is not defined in R, so there is no bar for cardinal, and neither does it contribute to the counts of “red”. Nevertheless, there is certainly evidence that if you want your hypothetical school to stand out, white, blue and gold are certainly bad options for the school color."
  },
  {
    "objectID": "tutorials/r_shiny.html",
    "href": "tutorials/r_shiny.html",
    "title": "Interactive applications with Shiny",
    "section": "",
    "text": "Shiny allows you to create interactive applications using R. These applications basically function as websites, and they allow the user to control various characteristics of the output procudes on the page by adjusting the inputs in a nice, user-friendly interface. That is, the user gets to control how data that is analyzed and visualized, without the need to write any code. You can host these applications on your local device, or on the Shiny server: this latter option allows anybody on the internet to find and use your app by visiting a URL.\nIn this tutorial, we discuss the basic layout of a Shiny app and some examples of customizing the user interface, including inputs, outputs and reactive elements. We also discuss how to publish your apps on the Shiny server, and some considerations that specifically apply to apps hosted on Shiny. Some elements of this tutorial are based on Joachim Goedhart’s A Shiny start - Tutorial. The final app script created in this tutorial is available here."
  },
  {
    "objectID": "tutorials/r_shiny.html#changing-the-data-adding-initial-data-cleaning",
    "href": "tutorials/r_shiny.html#changing-the-data-adding-initial-data-cleaning",
    "title": "Interactive applications with Shiny",
    "section": "Changing the data, adding initial data cleaning",
    "text": "Changing the data, adding initial data cleaning\nYou can use your own data in a Shiny app by loading it in the same way as you would in a regular R script. For example, you can load a CSV file with read_csv() from the readr package. In this case, let’s use the same dataset that we used in the data wrangling tutorial on animal species and their observed characteristics.\nYou should load any data that you want to use in the app before the UI and server functions. You should also undertake any data cleaning steps that don’t depend on user input there. You do this for the purpose of efficiency: code outside the server function is only run once, when the app is started, whereas code inside the server function is run every time the user changes an input.\nSo let’s add the code loading and cleaning the data to the top of the script; make sure to also load tidyverse together with the shiny package. In addition, let’s define a new tibble that summarizes the number of observations per year and per species so that later we can display these counts in a table in the app.\n\ndata &lt;- read_csv(\"https://raw.githubusercontent.com/ucrdatacenter/projects/main/apprenticeship/2024h1/1_intro/surveys.csv\")\n\nspecies_counts &lt;- data |&gt; \n  count(year, plot_type, genus, species)\n\nWe’ll be able to refer to these objects later when defining the server and ui functions."
  },
  {
    "objectID": "tutorials/r_shiny.html#specifying-new-inputs",
    "href": "tutorials/r_shiny.html#specifying-new-inputs",
    "title": "Interactive applications with Shiny",
    "section": "Specifying new inputs",
    "text": "Specifying new inputs\nThe default app contains a slider input that allows the user to control the number of bins in a histogram. This slider input is only one of many possible input elements that you can add to a Shiny app. You can add a text box, a dropdown menu, a checkbox, a radio button, a date picker, and more: the list of possible inputs is available on the right side of the first page of this cheatsheet, including the main arguments each input type takes (for the full list of arguments, check the relevant help files).\nLet’s add a few different input elements to the app.\nFirst, let’s adjust the existing slider input to allow the user to adjust the year range from which we’ll display data. You can modify the slider input by changing the arguments of the sliderInput() function as follows.\n\nsliderInput(\"years\", # input ID\n            \"Year range\", # displayed label\n            min = 1977, # minimum value\n            max = 2002, # maximum value\n            value = 1977 # initial value\n            )\n\nYou can also define the input characteristics by referencing the data you previously loaded. For example, you can make the slider range from the earliest to the latest year in the data by extracting the relevant information from your data.\n\nsliderInput(\"years\", # input ID\n            \"Year range\", # displayed label\n            min = min(data$year), # minimum value\n            max = max(data$year), # maximum value\n            value = c(min(data$year), max(data$year)) # initial value: two elements create a range\n            )\n\nNext, let’s add checkboxes that let the user display data from as many plot types as they want. If you want to add a single checkbox, you can use the checkboxInput() function, and for multiple checkboxes, you can use the checkboxGroupInput() function. In this case, let’s use all unique plot types in the data as the choices for the checkboxes, and let’s set the initial selection to select all plot types.\nMake sure that all your inputs are separated with commas inside your ui function.\n\ncheckboxGroupInput(\"plot_type\", # input ID\n                   \"Plot type\", # displayed label\n                   choices = unique(data$plot_type), # choices\n                   selected = unique(data$plot_type) # initial selection\n                   )\n\nFinally, let’s add two more inputs: a set of radio buttons that let the user choose which of the two numerical variables to plot, and a numeric input that lets the user control the number of bins in the histogram.\n\nradioButtons(\"variable\", # input ID\n             \"Displayed variable\", # displayed label\n             choiceNames = c(\"Hindfoot length\", \"Animal weight\"), # displayed choices\n             choiceValues = c(\"hindfoot_length\", \"weight\"), # values returned by input\n             ),\nnumericInput(\"bins\", \"Number of bins:\", 30)\n\nIf you run the app now, you’ll see all the inputs show up in the sidebar panel, and you can see how they are arranged and how you can change their values. However, they are not yet connected to any outputs, so changing their values doesn’t do anything yet. Fortunately you can introduce new UI elements that take user input, but are not yet connected to an action. This is nice, as it allows you to build the UI elements gradually without breaking the app."
  },
  {
    "objectID": "tutorials/r_shiny.html#specifying-new-outputs-that-depend-on-the-inputs",
    "href": "tutorials/r_shiny.html#specifying-new-outputs-that-depend-on-the-inputs",
    "title": "Interactive applications with Shiny",
    "section": "Specifying new outputs that depend on the inputs",
    "text": "Specifying new outputs that depend on the inputs\nThe default app creates a single output element: a histogram with the identifier “plot”. The ui function places this element in the main panel by including a plotOutput() in the mainPanel() function, specifying the identifier of the plot as the only argument. Then the server function provides the details of how to generate the plot by defining the element output$plot as a renderPlot({}) function (the curly braces inside the parentheses allow us to define the plot contents as a longer code chunk including intermediate objects, line breaks, etc.).\nLet’s modify this default plot and add a few more outputs to the app. To change the plot object to a histogram of the filtered data and selected variable, we can replace the current contents of the renderPlot({}) with code that takes our previously loaded data, filters it, and plots our selected variable.\nTo access the values of the inputs defined by the input UI elements, we can refer to them as input$input_id where input_id is the identifier of the input element. For example, to access the value of the years slider, we can use input$years – since input$years has two elements, one for the minimum year and one for the maximum year selected, we can access the individual elements by subsetting the input$years vector. Notice that instead of calling input$variable in the ggplot function directly, we are renaming the chosen variable to value, and referring to the value variable later. The reason for this is that ggplot expects the variable name to be an object, not a string (i.e. no quotation signs), but input$variable is a string. The rename() function, however, does not care whether variables are specified as objects or strings, so we can apply this trick instead of having to use more complex functions to convert character strings to objects.\n\ndata |&gt; \n  filter(year &gt;= input$years[1], year &lt;= input$years[2],\n         plot_type %in% input$plot_type) |&gt; \n  rename(\"value\" = input$variable) |&gt; \n  select(year, value, genus, species, plot_type) |&gt; \n  ggplot(aes(value)) +\n        geom_histogram(bins = input$bins) +\n        theme_light()\n\nDon’t be surprised that the previous function does not work outside of a Shiny app: the input object is only defined inside the server function, so you can only access it there. Therefore if you’d like to test your code, you can do that in two ways:\n\nRun the app and test it in the browser, making sure that all outputs look reasonable.\nCreate a new R script, load the data, and copy the code from the server function into the new script, replacing all input$input_id references vectors that you define in that new script. (I tend to define e.g. inputyears &lt;- c(1980, 2000) at the top of the script I use for this testing, since then the only thing I need to change in the copied server code is to remove the dollar signs $ from the input specifications.)\n\nNow let’s add some different output types to the app. The only difference between the different output types is the function that you use to define them in the ui and server functions: the ui function uses typeOutput() and the server function uses renderType(), where type is the type of output you want to create. The same cheatsheet linked above also contains a list of possible output types and the correspondence between ui and server functions (they are usually the same, but not always, see e.g. verbatimTextOutput and renderPrint).\nLet’s add a text output that displays the mean of the selected variable in the data filtered by the user’s choices, let’s call it summary. For that we can use the renderText() function in the server function, and the textOutput() function in the ui function. Again, the textOutput() just contains the object identifier, and the renderText() function contains a code chunk that generates the text to be displayed.\n\n# inside UI mainPanel() (make sure to separate from plotOutput() with a comma)\ntextOutput(\"summary\")\n\n# inside server (no commas needed between output elements)\noutput$summary &lt;- renderText({\n  mean &lt;- data |&gt; \n    filter(year &gt;= input$years[1], year &lt;= input$years[2],\n           plot_type %in% input$plot_type) |&gt; \n    rename(\"value\" = input$variable) |&gt; \n    pull(value) |&gt;\n    mean()\n  \n  paste0(\"Sample mean of \", input$variable, \":\\n\", mean)\n})\n\nFinally, let’s add a table that displays the number of different species observed in the filtered data. For this we can use our previously defined species_counts object, and the renderTable() and tableOutput() functions.\n\n# inside UI mainPanel()\ntableOutput(\"counts\")\n\n# inside server\noutput$counts &lt;- renderTable({\n  species_counts |&gt; \n    filter(year &gt;= input$years[1], year &lt;= input$years[2],\n           plot_type %in% input$plot_type) |&gt; \n    group_by(genus, species) |&gt; \n    summarize(n = sum(n))\n})\n\nSince the resulting table is quite long, it might be nicer to use another element type that gives more control over how the data is displayed: the dataTableOutput() and renderDataTable() functions from the DT package split the data to multiple pages, displaying only a certain number of observations at once, let the user sort the data based on each column, and additional arguments even allow the user to search for specific values in the table. So let’s install and load the DT package and change tableOutput to dataTableOutput() and renderTable() to renderDataTable() instead – no changes are needed in the function body.\n\n# inside UI mainPanel()\ndataTableOutput(\"counts\")\n\n# inside server\noutput$counts &lt;- renderDataTable({\n  species_counts |&gt; \n    filter(year &gt;= input$years[1], year &lt;= input$years[2],\n           plot_type %in% input$plot_type) |&gt; \n    group_by(genus, species) |&gt; \n    summarize(n = sum(n))\n})"
  },
  {
    "objectID": "tutorials/r_shiny.html#different-layout-options",
    "href": "tutorials/r_shiny.html#different-layout-options",
    "title": "Interactive applications with Shiny",
    "section": "Different layout options",
    "text": "Different layout options\nThe default app uses a sidebar layout, where the inputs are displayed in a sidebar panel on the left, and the outputs are displayed in the main panel on the right. A few possible options for different overall layout options are listed below.\n\nIf you remove the sidebarLayout(sidebarPanel(...), mainPanel(...)) function from the ui function and keep only the list of elements, the app will use a full-page layout instead, where the inputs and outputs are displayed one after the other.\nIf you replace the sidebarLayout(sidebarPanel(...), mainPanel(...)) function with tabsetPanel(tabPanel(...), tabPanel(...)), the app will use a tabbed layout, where the user can switch between different tabs, each displaying as a separate page.\nIf you replace the sidebarLayout(sidebarPanel(...), mainPanel(...)) function with fluidRow(column(...), column(...)), the app will use a column layout, where the inputs and outputs are displayed next to each other. You can adjust the width of each column and offset them to create space between the edges of the page and the page contents. Unlike the sidebar or tabset layouts, fluidRow() and column() can be used separately and interchangably: any elements inside the same fluidRow() are displayed next to each other, and any elements inside the same column() are displayed on top of each other.\nFor other layout options, see the Shiny layout guide and the Shiny cheatsheet linked above.\n\nNote that the all layouts explained above are still always inside a fluidPage() function, which should always be the outermost function in the ui function.\nIn addition to adjusting the overall layout, you can add other elements to the page to give it more structure on top of the inputs and outputs. Realize that the way the UI is structured is very similar to HTML script. After all, that’s exactly what’s happening in the background when you compile your app: R is generating HTML code that is then displayed in the browser. So it’s also possible to add other elements to the page that translate to HTML code: indeed, R has an extensive list of functions that generate HTML code, such as headers, paragraphs, horizontal lines, bold text, line breaks and more. For example, the h2(\"header text\") function in Shiny corresponds to &lt;h2&gt;header text&lt;/h2&gt; in HTML, while a separating line can be added with hr(). Again, the Shiny cheatsheet contains a longer list of these functions. So let’s add some of these elements to our current definition of the UI main panel to make the app outputs better structured.\n\nmainPanel(\n  h3(\"Histogram of chosen variable\"), # header for the plot\n  plotOutput(\"plot\"),\n  textOutput(\"summary\"),\n  hr(), # separating line between outputs\n  h3(\"Species counts\"), # header for the table\n  dataTableOutput(\"counts\")\n)"
  },
  {
    "objectID": "tutorials/r_shiny.html#reactive-objects",
    "href": "tutorials/r_shiny.html#reactive-objects",
    "title": "Interactive applications with Shiny",
    "section": "Reactive objects",
    "text": "Reactive objects\nNow that the app interface looks better, let’s make the code more efficient. Currently, much the code inside the renderPlot() and renderTable() functions is identical: we filter the data in the same way, and then we either plot or summarize the data. So it would be more efficient to define a new object inside the server that filters the data, and use that new, filtered data as the inputs both in the renderPlot() and renderTable() functions.\nThe problem is that you can’t define a new object inside the server function like how you would define a new object in a regular R script. Instead, you need to use a special function called reactive() that defines a new object that is reactive to the inputs. Once you’ve called the reactive({}) function, you can specify the code that defines the object inside the curly braces, and you can refer to the object in other elements of server by the name of the reactive object followed by parentheses (as if you were calling a function, which is technically what you’re doing).\nSo let’s add an element to the server code that defines a new reactive object called data_filtered that filters the data based on the user’s choices. Then we can replace the data object in the renderPlot() and renderTable() functions with data_filtered(). Make sure to define the reactive object before the output elements that use the object.\n\nserver &lt;- function(input, output) {\n  # define reactive object\n  data_filtered &lt;- reactive({\n    data |&gt; \n      filter(year &gt;= input$years[1], year &lt;= input$years[2],\n             plot_type %in% input$plot_type) |&gt; \n      rename(\"value\" = input$variable) |&gt; \n      select(year, value, genus, species, plot_type)\n  })\n  \n  output$plot &lt;- renderPlot({\n    # call reactive object and plot the value variable\n    data_filtered() |&gt;\n      ggplot(aes(value)) +\n      geom_histogram(bins = input$bins) +\n      theme_light()\n  })\n  \n  output$summary &lt;- renderText({\n    # call value variable from reactive object\n    paste0(\"Sample mean of \", input$variable, \":\\n\", mean(data_filtered()$value))\n  })\n}"
  },
  {
    "objectID": "tutorials/r_shiny.html#conditional-ui",
    "href": "tutorials/r_shiny.html#conditional-ui",
    "title": "Interactive applications with Shiny",
    "section": "Conditional UI",
    "text": "Conditional UI\nThe last change we’ll make to the app is to make the plot is to introduce a new input that appears on the interface only if a particular condition is satisfied. In this case, we want to add a checkbox that allows the user to facet the plot by plot type, but only if there is more than one plot type selected.\nThere are multiple ways to create conditional UI elements, such as via the conditionalPanel() function, or by using the shinyjs package that allows you to hide/show UI elements. In this tutorial we’ll use the uiOutput() and renderUI() functions, which allow you to define UI elements in the server function.\nInstead of specifying the details of the input element in the ui function, we use uiOutput() to define a placeholder. Then we use renderUI() to actually add the input function, wrapping it in an if-statement that evaluates the input function only if a logical condition is satisfied. So let’s add these elements to the app code.\n\n# inside UI sidebarPanel()\nuiOutput(\"facet_ui\") # UI element defined in server\n\n# inside server\noutput$facet_ui &lt;- renderUI({\n  # display facet option only if there is more than one facet\n  if (length(input$plot_type) &gt; 1) {\n    # UI element definition\n    checkboxInput(\"facet\", # input ID\n                  \"Facet by plot type?\", # displayed label\n                  FALSE # initial value\n    )\n  }\n})\n\nNow that we have this additional input (that outputs a logical value of length 1 for whether the plot should have facets), we need to adjust the plot output to facet the plot if input$facet == TRUE. So let’s add an if-statement to the renderPlot() function that adds the facetting if the checkbox is checked. To do so, we’ll break up the existing plotting function, assign the intermediate plot to an object, and then add the facetting to that object only if the checkbox is checked, and display the result.\n\noutput$plot &lt;- renderPlot({\n  # assign plot to object\n  p &lt;- data_filtered() |&gt;\n    ggplot(aes(value)) +\n    geom_histogram(bins = input$bins) +\n    theme_light()\n  \n  # add facetting if checkbox is checked\n  if (input$facet) p &lt;- p + facet_wrap(~plot_type)\n  \n  # display plot\n  p\n})"
  },
  {
    "objectID": "tutorials/r_stats.html",
    "href": "tutorials/r_stats.html",
    "title": "Statistics in R",
    "section": "",
    "text": "This document provides an overview of the basic statistical functions in R, including descriptive statistics and summary tables.\nThis tutorial shows you examples of using statistical methods on the diamonds dataset, which comes pre-loaded with the tidyverse package.\nLet’s load the tidyverse package and have a look at the diamonds dataset:\n\nlibrary(tidyverse)\ndata(diamonds)"
  },
  {
    "objectID": "tutorials/r_stats.html#summaries-in-the-r-console",
    "href": "tutorials/r_stats.html#summaries-in-the-r-console",
    "title": "Statistics in R",
    "section": "Summaries in the R Console",
    "text": "Summaries in the R Console\nTo get a descriptive statistic of a single variable in a tibble, we can use that variable as an argument to a relevant function (using $ to refer to a variable in a tibble).\n\nmean(diamonds$price)\nmedian(diamonds$price)\nsd(diamonds$price)\n\nTo get the frequencies of a categorical variable, we can use the count() function, with the sort = TRUE argument returning the values in descending frequency. count() is a tidy function that works well with pipe workflows and can count the joint frequencies of multiple variables.\n\n# frequencies of a single variable\ncount(diamonds, cut)\n\n# joint frequency distribution\ncount(diamonds, cut, color)\n\nTo get the correlation coefficient between two variables, we can use the cor() function in the same way we used other descriptives such as mean().\n\ncor(diamonds$price, diamonds$carat)\n\nThe easiest way to get summary statistics of all variables in a tibble is with the summary() function: this function shows the distribution of numeric variables, the frequencies of categorical variables, and the number of missing values for each variable.\n\nsummary(diamonds)"
  },
  {
    "objectID": "tutorials/r_stats.html#publication-ready-summaries-with-gtsummary",
    "href": "tutorials/r_stats.html#publication-ready-summaries-with-gtsummary",
    "title": "Statistics in R",
    "section": "Publication-ready summaries with gtsummary",
    "text": "Publication-ready summaries with gtsummary\nThe summary() function is useful for viewing the data in the Console, but doesn’t export to outside of R nicely. There are a few packages available for generating simple summary statistics tables that contain information about the central tendencies and dispersion of the data that also export nicely, such as gtsummary.\n\nlibrary(gtsummary)\n\n# tbl_summary() creates a summary table of the data\ntbl_summary(diamonds)\n\nYou can stratify your summary by a grouping variable using the by argument:\n\ntbl_summary(diamonds, by = cut)\n\n# add p-value of difference between groups\ntbl_summary(diamonds, by = cut) |&gt; \n  add_p()\n\nYou can also customize the appearance of the table.\n\ntbl_summary(diamonds, by = cut) |&gt; \n  modify_header(label ~ \"Variable\") |&gt; \n  modify_caption(\"Summary Table by Cut\")\n\nTo export the table as a Word document, use the gtsave() function. Note that we first use the as_gt() function to convert the tbl_summary() output to a gt object, and load the gt package in order to use the Word export function defined for the gt package.\n\nlibrary(gt)\n\ntbl_summary(diamonds, by = cut) |&gt; \n  as_gt() |&gt; \n  gtsave(\"summary_table.docx\")\n\nIf you use LaTeX, you can also export as a LaTeX table, also relying on the gt package.\n\ntbl_summary(diamonds, by = cut) |&gt; \n  as_gt() |&gt; \n  gtsave(\"summary_table.tex\")"
  },
  {
    "objectID": "tutorials/r_stats.html#t-tests",
    "href": "tutorials/r_stats.html#t-tests",
    "title": "Statistics in R",
    "section": "t-tests",
    "text": "t-tests\nWe can run one and two samples t-tests to evaluate group means with the t.test() function. The function supports various options and model specifications: a simple one-sample t-test only requires specifying the variable of interest, either with x = data$variable or x = variable, data = data syntax. For two-sample t-tests, we can use the formula syntax y ~ x to specify the dependent and independent variables or the x and y (and optionally data) arguments. Additional options include specifying the alternative hypothesis, the confidence level, the value of \\(\\mu\\), and whether we want a paired t-test and assume equal variances. Helper functions such as tidy() convert the Console output to an easy-to-export tibble of results.\nTo demonstrate two-sample t-tests, we define a subset of the data that contains only two possible values of cut.\n\n# simple t-test (H0: mean=mu)\nt.test(diamonds$carat, mu = 1)\n\n# define data subsample of fair and good diamonds to have only two groups of cut\ndiamonds_sub &lt;- diamonds |&gt; \n  filter(cut %in% c(\"Fair\", \"Good\"))\n\n# can also use data argument instead of data$...\n# price ~ cut is formula specification: variable ~ group\n# H0: fair and good diamonds have the same average price\nt.test(price ~ cut, alternative = \"greater\", data = diamonds_sub)\n\n# tidy() function turns results into a tibble\nt.test(price ~ cut, alternative = \"greater\", data = diamonds_sub) |&gt; tidy()"
  },
  {
    "objectID": "tutorials/r_stats.html#correlation-test",
    "href": "tutorials/r_stats.html#correlation-test",
    "title": "Statistics in R",
    "section": "Correlation test",
    "text": "Correlation test\nThe cor.test() function calculates the correlation between two variables. Again, the function supports various specifications: x and y arguments, formula syntax (see below for an example), and the data argument.\n\ncor.test( ~ price + carat, data = diamonds)\n\n# tidy() function turns results into a tibble\ncor.test( ~ price + carat, data = diamonds) |&gt; tidy()"
  },
  {
    "objectID": "tutorials/r_stats.html#simple-regression",
    "href": "tutorials/r_stats.html#simple-regression",
    "title": "Statistics in R",
    "section": "Simple regression",
    "text": "Simple regression\nA key building block of statistical analysis is linear regression. The lm() function fits a linear model to the data, with a wide range of specifications, passed as the formula argument (first argument if unnamed). The formula syntax is y ~ x, where y is the dependent variable and x is the independent variable. Again, optional function arguments allow for a lot of customization, but the default settings are sufficient for most applications. Helper functions such as tidy() and summary() provide extensive summaries of the model fit and coefficients, and tbl_regression() from the gtsummary package creates neat tables of the results. Assigning the result of a model to an object saves computational time, as then we can work with the results without having to re-run the analysis every time.\n\n# assign outcome to object\nfit &lt;- lm(price ~ carat, data = diamonds)\n\n# extensive result summary\nfit |&gt; summary()\n\n# tidy coefficients\nfit |&gt; tidy()\n\n# display-ready table with gtsummary\ntbl_regression(fit)"
  },
  {
    "objectID": "tutorials/r_stats.html#multiple-regression",
    "href": "tutorials/r_stats.html#multiple-regression",
    "title": "Statistics in R",
    "section": "Multiple regression",
    "text": "Multiple regression\nMultiple regression extends simple regression to multiple independent variables. The only difference is the formula specification, which now connects multiple independent variables with + signs. The formula specification also allows for interactions between variables, which can be specified with * (if the main effects should be included) or : (for only the interaction term). The DV ~ .~ syntax includes all variables in the data except the dependent variable as independent variables.\n\nlm(price ~ x + y + z + table + depth, data = diamonds) |&gt; summary()\n\n# all variables in data\nlm(price ~ ., data = diamonds) |&gt; summary()\n\n# interactions\nlm(price ~ x * y, data = diamonds) |&gt; summary()"
  },
  {
    "objectID": "tutorials/r_stats.html#anova",
    "href": "tutorials/r_stats.html#anova",
    "title": "Statistics in R",
    "section": "ANOVA",
    "text": "ANOVA\nAnalysis of variance (ANOVA) is a generalization of the t-test to multiple groups. The aov() function fits an ANOVA model to the data, with the formula syntax y ~ x, where y is the dependent variable and x is the independent variable. The same helper functions as with lm() can be used to summarize the results.\nNote that ANOVA is a specific case of a linear regression model, so the results are equivalent to those of a linear regression model with a categorical independent variable.\n\nanova_fit &lt;- aov(price ~ cut, data = diamonds)\n\nsummary(anova_fit)\ntidy(anova_fit)\n\n# equivalent regression\nlm(price ~ cut, data = diamonds) |&gt; summary()"
  },
  {
    "objectID": "tutorials.html",
    "href": "tutorials.html",
    "title": "Tutorials",
    "section": "",
    "text": "Setting up R\n\nStart here to learn how to use R.\n\nInstalling R"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact us",
    "section": "",
    "text": "The Data Center student fellows hold office hours in the Data Center’s office (Anne ground floor) to answer questions and help with assignments. Drop by to office hours if you’re looking for some data science help, whether for a data encounter in a course, another UCR course, or your SEPR!\n\nOffice hour schedule\nOffice hours are held in the Data Center’s office (Anne ground floor), every week during the semester between week 4 and week 15. You are welcome to drop by any time during the office hours, no appointment needed.\nOffice hours are with the current Data Center interns; you can learn more about their specific expertise below the schedule.\n\n\n\n\n\nMonday\nTuesday\nWednesday\nThursday\nFriday\n\n\n\n\n9:00-10:00\n\n\n\n\n\n\n\n10:00-11:00\n\n\n\nMichel\n\n\n\n11:00-12:00\nJulia\n\n\n\nLili\n\n\n12:00-13:00\n\n\n\n\nGabriela\n\n\n13:00-14:00\n\n\n\n\n\n\n\n14:00-15:00\n\nMare\n\n\n\n\n\n15:00-16:00\n\n\nMichel\n\n\n\n\n16:00-17:00\nClement\n\n\n\n\n\n\n17:00-18:00\nMichel\n\n\n\n\n\n\n18:00-19:00\n\n\n\n\n\n\n\n\n\nClement: Spatial data, rasters, maps, Ecology\nGabriela: R, Python, Stata, SQL (soon), statistics, visualization, data tidying and transformation, data import/export, spatial data\nJulia: R, data cleaning and wrangling, data visualization, statistics\nLili: R, text analysis, character strings\nMare: Basic R and Python; Working with Corpora / Text analysis\nMichel: Data Science in R: Data wrangling, spatial data, data visualizations and simple text analysis\n\n\n\nContact us\nIf you would like to request an individual consultation, or would like to know more about becoming an intern for the Data Center, feel free to send an email to datacenter@ucr.nl.\nMake sure to check this website for news and updates, and follow us on Instagram!"
  }
]
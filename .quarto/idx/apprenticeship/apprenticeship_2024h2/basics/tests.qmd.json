{"title":"Data Center Apprenticeship:\nR basics: Hypothesis testing / modelling","markdown":{"yaml":{"title":"Data Center Apprenticeship:\nR basics: Hypothesis testing / modelling","subtitle":"June 2024","date":"Last updated: `r Sys.Date()`"},"headingText":"t-tests","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)\n```\n\n```{r, echo=FALSE}\nlibrary(tidyverse)\nlibrary(stargazer)\ndata <- read_csv(\"data/data.csv\")\n```\n\nMost of the simple statistical tests are from base R, so they don't rely on tidy principles, but many are compatible with tidy workflows to at least some extent. In the following we'll cover some of the key methods that show up in methods and statistics courses at UCR. In addition, the `tidy()` function from the `broom` package converts most text output into simple tibblesy, which are useful for exporting and visualizing results.\n\n\nWe can run one and two samples t-tests to evaluate group means with the `t.test()` function. The function supports various options and model specifications: a simple one-sample t-test only requires specifying the variable of interest, either with `x = data$variable` or `x = variable, data = data` syntax. For two-sample t-tests, we can use the formula syntax `y ~ x` to specify the dependent and independent variables or the `x` and `y` (and optionally `data`) arguments. Additional options include specifying the alternative hypothesis, the confidence level, the value of $\\mu$, and whether we want a paired t-test and assume equal variances. Helper functions such as `tidy()` convert the Console output to an easy-to-export tibble of results.\n\n```{r}\nlibrary(broom) # for tidy() function\n\n# simple t-test (H0: mean=mu)\nt.test(data$scholarship, mu = 50)\n\n# use data argument instead of data$... to work in pipe workflows\ndata |> \n  # grade ~ reading is formula specification: variable ~ group\n  # _ is placeholder if the pipe input is not the first argument of the next function\n  t.test(grade ~ reading, alternative = \"greater\", data = _)\n\ndata |> \n  t.test(grade ~ reading, alternative = \"greater\", data = _) |> \n  tidy()\n```\n\n# Correlation test\n\nThe `cor.test()` function calculates the correlation between two variables. Again, the function supports various specifications: `x` and `y` arguments, formula syntax (see below for an example), and the `data` argument.\n\n```{r}\ncor.test( ~ grade + age, data = data)\n\n# assign the outcome to an object\ncor_result <- cor.test( ~ grade + age, data = data)\n# tibble of results\ntidy(cor_result)\n```\n\n# Simple regression\n\nA key building block of statistical analysis is linear regression. The `lm()` function fits a linear model to the data, with a wide range of specifications, passed as the formula argument (first argument if unnamed). The formula syntax is `y ~ x`, where `y` is the dependent variable and `x` is the independent variable. Again, optional function arguments allow for a lot of customization, but the default settings are sufficient for most applications. Helper functions such as `tidy()` and `summary()` provide extensive summaries of the model fit and coefficients, and `stargazer()` creates neat tables of the results. Assigning the result of a model to an object saves computational time, as then we can work with the results without having to re-run the analysis every time.\n\n```{r}\n# assign outcome to object\nfit <- lm(grade ~ age, data = data)\n\n# extensive result summary\nfit |> summary()\n\n# tidy coefficients\nfit |> tidy()\n\n# display-ready table\nfit |> \n  stargazer(type = \"text\", title = \"Grade - agre regression results\")\n```\n\n# Multiple regression\n\nMultiple regression extends simple regression to multiple independent variables. The only difference is the formula specification, which now connects multiple independent variables with `+` signs. The formula specification also allows for interactions between variables, which can be specified with `*` (if the main effects should be included) or `:` (for only the interaction term). The `DV ~ .~` syntax includes all variables in the data except the dependent variable as independent variables.\n\n```{r}\nlm(grade ~ age + scholarship, data = data) |> summary()\n\n# all variables in data\nlm(grade ~ ., data = data) |> summary()\n\n# interactions\nlm(grade ~ age * scholarship, data = data) |> summary()\n```\n\n# ANOVA\n\nAnalysis of variance (ANOVA) is a generalization of the t-test to multiple groups. The `aov()` function fits an ANOVA model to the data, with the formula syntax `y ~ x`, where `y` is the dependent variable and `x` is the independent variable. The same helper functions as with `lm()` can be used to summarize the results.\n\nNote that ANOVA is a specific case of a linear regression model, so the results are equivalent to those of a linear regression model with a categorical independent variable.\n\n```{r}\nanova_fit <- aov(grade ~ reading, data = data)\n\nsummary(anova_fit)\ntidy(anova_fit)\n\n# equivalent regression\nlm(grade ~ reading, data = data) |> summary()\n```\n\n# Chi-square test\n\nThe chi-square test is used to test the independence of two categorical variables. The `chisq.test()` function calculates the chi-square statistic and the p-value for the test. Unlike the previous functions, the function does not allow for a `data` argument, and is therefore difficult to implement in tidy workflows.\n\n```{r}\nchisq.test(data$reading, data$notes)\n```\n\nAdd contingency tables:\n\n```{r}\n# with table()\ntable(data$reading, data$notes)\n\n# with xtabs()\nxtabs(~ reading + notes, data = data)\n\n# with count() and pivot_wider()\ndata |> \n  count(reading, notes) |>\n  pivot_wider(names_from = notes, values_from = n, values_fill = 0)\n\n# proportions with table() and prop.table()\ntable(data$reading, data$notes) |> prop.table()\n\n# proportions with count() and pivot_wider()\ndata |> \n  count(reading, notes) |>\n  mutate(prop = n / sum(n)) |>\n  select(-n) |> \n  pivot_wider(names_from = notes, values_from = prop, values_fill = 0)\n\n```\n\n# Logistic regression\n\nWhen it comes to predicting binary outcomes, linear regression has some problems, such as predicting values outside the 0-1 range. Therefore in those cases, we often use logistic regression instead. The `glm()` function fits a logistic regression model to the data. Other than the `family` argument, which specifies the distribution of the dependent variable, the function works in the same as `lm()`. A logistic regression uses `family = \"binomial\"`.\n\n```{r}\nlogit_fit <- glm(reading ~ age, data = data, family = \"binomial\")\n\nlogit_fit |> summary()\nlogit_fit |> tidy()\n\n# display-ready table\nstargazer(logit_fit, type = \"text\", \n          title = \"Relationship between doing the reading and age\")\n\n```\n\n# Non-parametric tests\n\nNon-parametric tests are used when the assumptions of parametric tests are violated. Running them in R follows the same structure as running the parametric alternative, other than the function name itself and potential alternative optional arguments.\n\n```{r}\n# Wilcoxon signed-rank test\nwilcox.test(data$grade, mu = 2)\n\n# Mann-Whitney U test\nwilcox.test(grade ~ reading, data = data)\n\n# Kruskal-Wallis test (scholarship is a number in the data so convert to factor for this example)\nkruskal.test(grade ~ factor(scholarship), data = data)\n```\n\n# PCA and factor analysis\n\nPrincipal component analysis (PCA) and factor analysis are used to reduce the dimensionality of a dataset. The `prcomp()` function fits a PCA model to the data, and the `factanal()` function fits a factor analysis model. Both functions work with the formula syntax, and the `data` argument can be used to specify the data frame.\n\n```{r}\n# PCA\npca_fit <- prcomp(~ grade + age + scholarship, data = data)\n\n# summary of PCA\nsummary(pca_fit)\n# component loadings for each observation\ntidy(pca_fit)\n\n# Factor analysis\nfa_fit <- factanal(~ grade + age + scholarship, factors = 1, data = data)\n\n# summary of factor analysis\nfa_fit\ntidy(fa_fit)\n```\n\n# Repeated measures ANOVA\n\nRepeated measures ANOVA is used when the same subjects are measured multiple times. The `aov()` function can be used to fit these models, with the formula syntax `y ~ x + Error(subject)`, where `y` is the dependent variable, `x` is the independent variable, and `subject` is the repeated measure. The `Error()` function specifies the repeated measure, and the `data` argument can be used to specify the data frame.\n\n```{r}\n# repeated measures ANOVA\n# redefine data to have two observations per person, the second with random noise added to the grade\nbind_rows(data,\n          data %>% mutate(grade = grade + rnorm(n()))) |>\n  aov(grade ~ reading + Error(id), data = _)\n```\n\n# Go to\n\n-   [Introduction to R](../intro)\n-   [Finding and importing data](../import)\n-   [Data cleaning with `dplyr`](../clean)\n-   [Summary statistics](../summary)\n-   [Data visualization with `ggplot2`](../ggplot)\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)\n```\n\n```{r, echo=FALSE}\nlibrary(tidyverse)\nlibrary(stargazer)\ndata <- read_csv(\"data/data.csv\")\n```\n\nMost of the simple statistical tests are from base R, so they don't rely on tidy principles, but many are compatible with tidy workflows to at least some extent. In the following we'll cover some of the key methods that show up in methods and statistics courses at UCR. In addition, the `tidy()` function from the `broom` package converts most text output into simple tibblesy, which are useful for exporting and visualizing results.\n\n# t-tests\n\nWe can run one and two samples t-tests to evaluate group means with the `t.test()` function. The function supports various options and model specifications: a simple one-sample t-test only requires specifying the variable of interest, either with `x = data$variable` or `x = variable, data = data` syntax. For two-sample t-tests, we can use the formula syntax `y ~ x` to specify the dependent and independent variables or the `x` and `y` (and optionally `data`) arguments. Additional options include specifying the alternative hypothesis, the confidence level, the value of $\\mu$, and whether we want a paired t-test and assume equal variances. Helper functions such as `tidy()` convert the Console output to an easy-to-export tibble of results.\n\n```{r}\nlibrary(broom) # for tidy() function\n\n# simple t-test (H0: mean=mu)\nt.test(data$scholarship, mu = 50)\n\n# use data argument instead of data$... to work in pipe workflows\ndata |> \n  # grade ~ reading is formula specification: variable ~ group\n  # _ is placeholder if the pipe input is not the first argument of the next function\n  t.test(grade ~ reading, alternative = \"greater\", data = _)\n\ndata |> \n  t.test(grade ~ reading, alternative = \"greater\", data = _) |> \n  tidy()\n```\n\n# Correlation test\n\nThe `cor.test()` function calculates the correlation between two variables. Again, the function supports various specifications: `x` and `y` arguments, formula syntax (see below for an example), and the `data` argument.\n\n```{r}\ncor.test( ~ grade + age, data = data)\n\n# assign the outcome to an object\ncor_result <- cor.test( ~ grade + age, data = data)\n# tibble of results\ntidy(cor_result)\n```\n\n# Simple regression\n\nA key building block of statistical analysis is linear regression. The `lm()` function fits a linear model to the data, with a wide range of specifications, passed as the formula argument (first argument if unnamed). The formula syntax is `y ~ x`, where `y` is the dependent variable and `x` is the independent variable. Again, optional function arguments allow for a lot of customization, but the default settings are sufficient for most applications. Helper functions such as `tidy()` and `summary()` provide extensive summaries of the model fit and coefficients, and `stargazer()` creates neat tables of the results. Assigning the result of a model to an object saves computational time, as then we can work with the results without having to re-run the analysis every time.\n\n```{r}\n# assign outcome to object\nfit <- lm(grade ~ age, data = data)\n\n# extensive result summary\nfit |> summary()\n\n# tidy coefficients\nfit |> tidy()\n\n# display-ready table\nfit |> \n  stargazer(type = \"text\", title = \"Grade - agre regression results\")\n```\n\n# Multiple regression\n\nMultiple regression extends simple regression to multiple independent variables. The only difference is the formula specification, which now connects multiple independent variables with `+` signs. The formula specification also allows for interactions between variables, which can be specified with `*` (if the main effects should be included) or `:` (for only the interaction term). The `DV ~ .~` syntax includes all variables in the data except the dependent variable as independent variables.\n\n```{r}\nlm(grade ~ age + scholarship, data = data) |> summary()\n\n# all variables in data\nlm(grade ~ ., data = data) |> summary()\n\n# interactions\nlm(grade ~ age * scholarship, data = data) |> summary()\n```\n\n# ANOVA\n\nAnalysis of variance (ANOVA) is a generalization of the t-test to multiple groups. The `aov()` function fits an ANOVA model to the data, with the formula syntax `y ~ x`, where `y` is the dependent variable and `x` is the independent variable. The same helper functions as with `lm()` can be used to summarize the results.\n\nNote that ANOVA is a specific case of a linear regression model, so the results are equivalent to those of a linear regression model with a categorical independent variable.\n\n```{r}\nanova_fit <- aov(grade ~ reading, data = data)\n\nsummary(anova_fit)\ntidy(anova_fit)\n\n# equivalent regression\nlm(grade ~ reading, data = data) |> summary()\n```\n\n# Chi-square test\n\nThe chi-square test is used to test the independence of two categorical variables. The `chisq.test()` function calculates the chi-square statistic and the p-value for the test. Unlike the previous functions, the function does not allow for a `data` argument, and is therefore difficult to implement in tidy workflows.\n\n```{r}\nchisq.test(data$reading, data$notes)\n```\n\nAdd contingency tables:\n\n```{r}\n# with table()\ntable(data$reading, data$notes)\n\n# with xtabs()\nxtabs(~ reading + notes, data = data)\n\n# with count() and pivot_wider()\ndata |> \n  count(reading, notes) |>\n  pivot_wider(names_from = notes, values_from = n, values_fill = 0)\n\n# proportions with table() and prop.table()\ntable(data$reading, data$notes) |> prop.table()\n\n# proportions with count() and pivot_wider()\ndata |> \n  count(reading, notes) |>\n  mutate(prop = n / sum(n)) |>\n  select(-n) |> \n  pivot_wider(names_from = notes, values_from = prop, values_fill = 0)\n\n```\n\n# Logistic regression\n\nWhen it comes to predicting binary outcomes, linear regression has some problems, such as predicting values outside the 0-1 range. Therefore in those cases, we often use logistic regression instead. The `glm()` function fits a logistic regression model to the data. Other than the `family` argument, which specifies the distribution of the dependent variable, the function works in the same as `lm()`. A logistic regression uses `family = \"binomial\"`.\n\n```{r}\nlogit_fit <- glm(reading ~ age, data = data, family = \"binomial\")\n\nlogit_fit |> summary()\nlogit_fit |> tidy()\n\n# display-ready table\nstargazer(logit_fit, type = \"text\", \n          title = \"Relationship between doing the reading and age\")\n\n```\n\n# Non-parametric tests\n\nNon-parametric tests are used when the assumptions of parametric tests are violated. Running them in R follows the same structure as running the parametric alternative, other than the function name itself and potential alternative optional arguments.\n\n```{r}\n# Wilcoxon signed-rank test\nwilcox.test(data$grade, mu = 2)\n\n# Mann-Whitney U test\nwilcox.test(grade ~ reading, data = data)\n\n# Kruskal-Wallis test (scholarship is a number in the data so convert to factor for this example)\nkruskal.test(grade ~ factor(scholarship), data = data)\n```\n\n# PCA and factor analysis\n\nPrincipal component analysis (PCA) and factor analysis are used to reduce the dimensionality of a dataset. The `prcomp()` function fits a PCA model to the data, and the `factanal()` function fits a factor analysis model. Both functions work with the formula syntax, and the `data` argument can be used to specify the data frame.\n\n```{r}\n# PCA\npca_fit <- prcomp(~ grade + age + scholarship, data = data)\n\n# summary of PCA\nsummary(pca_fit)\n# component loadings for each observation\ntidy(pca_fit)\n\n# Factor analysis\nfa_fit <- factanal(~ grade + age + scholarship, factors = 1, data = data)\n\n# summary of factor analysis\nfa_fit\ntidy(fa_fit)\n```\n\n# Repeated measures ANOVA\n\nRepeated measures ANOVA is used when the same subjects are measured multiple times. The `aov()` function can be used to fit these models, with the formula syntax `y ~ x + Error(subject)`, where `y` is the dependent variable, `x` is the independent variable, and `subject` is the repeated measure. The `Error()` function specifies the repeated measure, and the `data` argument can be used to specify the data frame.\n\n```{r}\n# repeated measures ANOVA\n# redefine data to have two observations per person, the second with random noise added to the grade\nbind_rows(data,\n          data %>% mutate(grade = grade + rnorm(n()))) |>\n  aov(grade ~ reading + Error(id), data = _)\n```\n\n# Go to\n\n-   [Introduction to R](../intro)\n-   [Finding and importing data](../import)\n-   [Data cleaning with `dplyr`](../clean)\n-   [Summary statistics](../summary)\n-   [Data visualization with `ggplot2`](../ggplot)\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"tests.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":"simplex","mainfont":"Cormorant SC","fontsize":"20px","title":"Data Center Apprenticeship:\nR basics: Hypothesis testing / modelling","subtitle":"June 2024","date":"Last updated: `r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
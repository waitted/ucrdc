{"title":"Data Center Apprenticeship: Introduction to data wrangling in R","markdown":{"yaml":{"title":"Data Center Apprenticeship: Introduction to data wrangling in R","subtitle":"January 2025","date":"Last updated: `r Sys.Date()`"},"headingText":"Objectives","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)\n```\n\n\n## Why R?\n\n-   Free and open-source\n-   Reproducible\n-   Widely used in academia and industry; up-to-date with the latest technological developments\n-   Very versatile: extensive package ecosystem for statistics and more\n-   Powerful data wrangling and visualization capabilities\n-   Extensive community support (open-access books, tutorials, forums, AI tools, etc.)\n\n## Why `tidyverse`?\n\n-   Clean, consistent, intuitive, readable syntax for all steps of the data analysis process\n-   Limited set of functions that can be combined in many ways\n-   Many packages beyond core `tidyverse` with the same underlying design, grammar, and data structures, therefore easier to learn advanced techniques\n\n# Introduction to R\n\n## Objects in R\n\nOne of the most basic types of objects in R is a vector. A vector is a collection of values of the same type, such as numbers, characters, or logicals (TRUE/FALSE). You can create a vector with the `c()` function, which stands for concatenate. If you assign a vector to an object with the assignment operator `<-`, your vector will be saved in your environment so you can work with it within your current R session. Some examples of creating vectors are:\n\n```{r}\nv1 <- c(\"A\", \"B\", \"C\")  # character vector with 3 elements\nv2 <- 25                # numeric vector with 1 element\nv3 <- 1:10              # numeric vector with 10 elements - integers from 1 to 10\n```\n\nTo subset or extract elements from a vector, you can use square brackets `[ ]` with an index. For example, `v1[1]` returns the first element of `v1`, `v3[2:5]` returns the 2nd to 5th elements of `v3`, and `v3[-c(2, 4, 6)]` returns all but the 2nd, 4th and 6th elements of `v3`.\n\n```{r}\nv1[1]\nv3[2:5]\nv3[-c(2, 4, 6)]\n```\n\nA dataframe (or \"tibble\" in `tidyverse`) is a special type of object that combines vectors into a rectangular table. Each column of a dataframe is a vector, and each row is an observation. usually you would load data from an external source, but you can create a dataframe with the `data.frame()` and a tibble with the `tibble()` function. You can also convert other data types such as matrices to tibbles with the `as_tibble()` function. Both functions take vectors as their arguments. Tibbles are preferred because they are more modern and have some convenient features that dataframes don't, but for the most part, differences are minor and for the most part it does not matter whether you work with tibbles or dataframes.\n\nA simple example of creating a tibble is (make sure to load `tidyverse` first):\n\n```{r}\nlibrary(tidyverse)\n\n# define vectors within the tibble() function\ntibble(\n  name = c(\"Alice\", \"Bob\", \"Chris\"),\n  height = c(165, 180, 175)\n)\n\n# define the vectors first, then combine them into a tibble\nname <- c(\"Alice\", \"Bob\", \"Chris\")\nheight <- c(165, 180, 175)\ntibble(name, height)\n```\n\n## Functions in R\n\nFunctions are reusable pieces of code that perform a specific task. They take arguments as inputs and return one or more pieces of output. You will mostly work with functions loaded from various packages or from the base R distribution, and in some cases you may write your own functions to avoid repetition or improve the readability of your code. We will cover writing your own functions later in the program.\n\nAs with vectors, the output of a function is saved to your environment only if you assign the result to an object. For example, `sum(x)` will display the sum of the elements of the vector `x`, but `sum <- sum(x)` will save this result to an object.\n\n```{r}\nx <- c(1, 5, 6, 2, 1, 8)\n\nsum(x)\nsum <- sum(x)\n```\n\nSome important functions on vectors are\n\n```{r}\nmean(x)   # return the mean; add the argument na.rm = TRUE if missing values should be excluded\nlength(x) # give the length of the vector (number of elements)\nunique(x) # list the unique elements of the vector\n```\n\nTo learn more about a function and its arguments, you can use the ? operator or the help() function, for example by typing `?sum` (or equivalently, `?sum()`). It is good practice to request help files from your console and not you R script, since there is no need to save these queries for the future.\n\n# Importing data\n\nR can handle practically any type of data, from simple text files to files used by other (not necessarily open-source) software and complex databases. This gives users a lot of flexibility in terms of data sources and formats.\n\nIn addition to using your own data (e.g. as exported from a survey), the Data Center keeps a continuously updated list of useful datasets by discipline, accessible [here](../../../../tutorials/data).\n\nIn the following, we'll discuss how to import and export from and to various file formats, and discuss a number of available packages to do so.\n\nStart by reading the introduction to importing the most common file types (text files, Excel, SPSS, Stata) [here](../../../../tutorials/r_adv_import). It is good to be aware of the Import dataset button and use it when needed, but in the long run it is easier to be aware of the available import functions and use them directly. The rest of this section gives more information and examples of importing data from different file formats and different levels of tidiness.\n\nWe will use the following packages for importing different file formats:\n\n```{r}\nlibrary(tidyverse)\nlibrary(readxl) # for Excel\nlibrary(haven) # for SPSS, Stata, SAS\n```\n\nIn addition, the `rio` package provides a generic import function, however, it is simply a wrapper for many of the other import functions shown below. While it may be easier to use the same import function for many file formats, `rio` redirects you to the original functions if you look for the possible function arguments, therefore for debugging it is better practice to use the \"original\" functions. In some cases, `rio` can read URL file paths that `readr` and `readxl` can't.\n\nIn the following, we'll work with some example data of student characteristics and grades. First, download [this](https://github.com/ucrdatacenter/projects/raw/refs/heads/main/apprenticeship/2025h1/student_data.zip) zip-file from GitHub, and extract it into a data folder within your apprenticeship project directory. We now import each file, explaining the packages, functions, and function arguments used. These files are all different subsets of the same dataset on student characteristics and grades at a university ([original source](https://www.kaggle.com/datasets/jacksondivakarr/student-classification-dataset?resource=download)).\n\n`student1.csv` is a comma-separated text file. Opening it in a notepad or Excel shows that the column separators are commas (,). The `read_csv()` function from the previous workshop expects commas as a separator, while `read_csv2()` expects semicolons (common with e.g. Dutch language settings). Since CSV files are a form of delimited text files, we can also use the more versatile `read_delim()` function specifying the delimiter as the argument.\n\nIn the following, we use the `read_csv()` (and `read_delim()`) function to import the data, and assign the resulting object to an object called `student1` with the assignment operator `<-`. The `student1` object is now a tibble in the R environment: you can find the object in the Environment tab in RStudio, and view the data by clicking on the object name or running `View(student1)` in the Console.\n\n```{r}\nstudent1 <- read_csv(\"data/student1.csv\")\nstudent1 <- read_delim(\"data/student1.csv\", delim = \",\")\n```\n\nIn this case, we used `read_csv()` only specifying its one mandatory argument: the file path. When using `read_delim()`, we also specified an optional argument: we defined the delimiter as a comma, thereby overriding the default function behavior. To learn more about the mandatory and optional arguments of a function, and find out what the default behaviors are, you can use the `?` operator followed by the function name, e.g. `?read_delim` in the Console to open the help file of a function (or use the search bar of the Help tab).\n\n`student2.tab` is also a delimited text file. Opening it in a notepad shows that the delimiter is a tab. The notation for tab whitespace is `\\t`, which we can specify in the `delim` argument. Like the \".tab\" file extension, \".tsv\" is also a tab-separated text file, so the more specialized `read_tsv()` function also works.\n\nIf you load this data without optional arguments, you'll see that instead of the correct number of columns, we get a single column, with the variable name containing some metadata. To get the correct number of columns, we need to skip the first row of the data that contains this metadata, as the actual data starts from the second row. We can use the `skip` argument to skip the first row. If we use one of the relevant import functions, and assign the outcome to the `student2` object, we can see that the data is now correctly imported and shows up in the environment next to `student1` as another tibble.\n\n```{r}\nstudent2 <- read_delim(\"data/student2.tab\", delim = \"\\t\", skip = 1)\nstudent2 <- read_tsv(\"data/student2.tab\", skip = 1)\n```\n\n`student3.xlsx` is an Excel file. To import Excel file we need the `read_excel()` function from the `readxl` package (the `readxl` package is one of packages that is not a part of core `tidyverse` but uses the same principles). With the `read_excel()` function you can specify which sheet to use in addition to similar arguments as for delimited text files. Notice that by default R imports the \"Metadata\" sheet, so we can use the `sheet` argument to specify which sheet to import. In addition, the first two rows contain introductory text, not the data, so we can use the `skip` argument to skip those rows. You may also notice that previously the variable name for age was `Student_Age` and now it is `Student_age`. You can rename the variable either by giving a full list of column names in the import function, but often it is easier to use the `rename()` function after importing.\n\n```{r}\nstudent3 <- read_excel(\"data/student3.xlsx\", sheet = \"Data\")\n```\n\nThe `haven` package (also not core `tidyverse` but same principles) reads files in the data formats of SPSS (.sav) and Stata (.dta). It can also extract variable and value labels from these files; here we can use the `read_spss()` to import `student4.sav`.\n\n```{r}\nstudent4 <- read_spss(\"data/student4.sav\")\n```\n\nRDS is an R-specific file format that saves all attributes of the dataframe (e.g. grouping, factor levels). It is particularly useful for saving intermediate data files, e.g. saving the cleaned data before analysis to avoid needing to run the data cleaning script repeatedly. To import an RDS file such as `student5.rds`, use the `read_rds()` function.\n\n```{r}\nstudent5 <- read_rds(\"data/student5.rds\")\n```\n\nA few notes regarding importing and exporting data:\n\n-   Always make sure you know your current working directory and the relative path to your data directory. It is better to use relative rather than absolute file paths (i.e. `data/data.csv` instead of `C:/User/Project/data/data.csv`).\n-   Note that if you are using Windows, you may need to replace the backslashes (\\\\) in the file path with forward slashes (/) to avoid errors.\n-   You can import files directly from URLs, although you usually need the URL of a raw file. If a file downloads immediately instead of opening in a raw format, you can try to copy that download link by right-clicking and selecting \"Copy link address\"; the `import()` function from `rio` might be successful with those links.\n-   To export data from R, you can almost always use the `write_...()` function corresponding to the desired file format, e.g. `write_csv()`. For Excel files the preferred export function is `write_xlsx()`, and for SPSS's .sav files it is `write_sav()`.\n-   For other file formats, the generic `write()` function is useful; you can specify any file format, and if your input data is readable in the chosen format, the file will export properly.\n-   In all `write_()` functions you need to specify the data you'd like to save and the output file path (absolute or relative) including chosen file extension.\n\n```{r, eval=FALSE}\n# example export code\nwrite_csv(student1, \"data/new_data.csv\")\n```\n\n# Data wrangling\n\nData wrangling is the process of cleaning, structuring, and enriching raw data into a more usable format. The `dplyr` package is a part of the `tidyverse` and provides a set of functions that can be combined to perform the most common data wrangling tasks. The package is built around the concept of the \"grammar of data manipulation\", which is a consistent set of verbs that can be combined in many ways to achieve the desired result.\n\nThe main functions in `dplyr` are `filter()`, `select()`, `mutate()`, `arrange()`, `group_by()`, `summarize()`, and `rename()`. `dplyr` also provides a set of functions for combining datasets: `bind_rows()` and `bind_cols()` for row-wise and column-wise binding, and `left_join()`, `right_join()`, `inner_join()`, and `full_join()` for joining datasets based on common variables. These functions can be combined using the pipe operator `|>` (or `%>%`, they are mostly equivalent) to create a data wrangling workflow. The pipe operator takes the output of the function on its left and passes it as the first argument to the function on its right. This allows you to chain multiple functions together in a single line of code, making your code more readable and easier to understand.\n\nIn the following, we'll work with the `student` datasets imported in the previous section and show how to use the main `dplyr` functions to clean the data so it is suitable for analysis. These steps are useful even if the input data is quite clean, as we often need to work with only a subset of observations/variables, define new variables, or aggregate the data.\n\n## Merging datasets\n\nIn our current application, we have five datasets that contain different observations of the same, larger dataset. So we can list all datasets in a row-binding function to combine them into a single dataset called `student`.\n\n```{r}\nstudent <- bind_rows(student1, student2, student3, student4, student5)\n```\n\nIn the following, we'll demonstrate the key data cleaning functions on this merged tibble.\n\n## Filtering observations\n\nIf we want to keep only a subset of observations, we can use the `filter()` function. We can specify a logical condition as the argument to `filter()`, and only observations that meet that condition will be kept. For example, to keep only students who are over 21 years old, we can use the following code:\n\n```{r}\nfilter(student, Student_Age > 21)\n```\n\nIn a pipe workflow, the same code would look like this:\n\n```{r}\nstudent |> \n  filter(Student_Age > 21)\n```\n\nWe can also apply logical conditions to character variables, e.g. to keep only students who went to a private high school and who did not receive a failing grade. Filters can be combined with AND (`,` or `&`) and OR (`|`) operators into a single function. Note the use of quotation marks around the character values in the logical condition and the double equal sign `==` to denote equality.\n\n```{r}\nstudent |> \n  filter(High_School_Type == \"Private\", Grade != \"Fail\") \n```\n\nAnother useful logical operator is `%in%`, which allows you to filter observations based on a list of values. For example, to keep only students who receive either 75% or 100% scholarships, we can use the following code:\n\n```{r}\nstudent |> \n  filter(Scholarship %in% c(\"75%\", \"100%\"))\n```\n\n## Selecting variables\n\nIf we want to keep only a subset of variables, we can use the `select()` function. We can specify the variables we want to keep (or exclude, with `-` signs) as the arguments to `select()`, and only those variables will be kept. For example, to keep only the `Id` and `Student_Age` variables, we can use the following code:\n\n```{r}\nselect(student, Id, Student_Age)\n```\n\nWe can also select columns based on their location in the dataframe or by looking for patterns in the column names:\n\n```{r}\nselect(student, 1:3) # select the first three columns\nselect(student, starts_with(\"Student\")) # select columns that start with \"Student\"\nselect(student, -Grade) # keep everything but \"Grade\"\nselect(student, -c(2, 6, 10)) # keep everything but the 2nd, 6th, and 10th columns\n```\n\nA pipe workflow allows us to combine the filtering and selecting operations into a single, step-by-step workflow:\n\n```{r}\nstudent |> \n  filter(Student_Age > 21) |> \n  select(Id, Student_Age)\n```\n\n## Creating new variables\n\nIf we want to create a new variable based on existing variables, we can use the `mutate()` function. We can specify the new variable name and the calculation for the new variable as the arguments to `mutate()`, and the new variable will be added to the dataset. For example, we can create a new variable `Daily_Study_Hours` that divides `Weekly_Study_Hours` by 5, a new variable `Class_Participation` that is a logical variable indicating whether the student has at least one \"Yes\" answer for reading, listening, and taking notes, and a new variable `Scholarship_num` that extracts the numeric value of `Scholarship` if the string contains a number.\n\n```{r}\nstudent |> \n  # create new variables\n  mutate(Daily_Study_Hours = Weekly_Study_Hours / 5,\n         Class_Participation = Reading == \"Yes\" | Listening_in_Class == \"Yes\" | Notes == \"Yes\",\n         Scholarship_num = parse_number(Scholarship)) |> \n  # show only ID and the new variables\n  select(Id, Daily_Study_Hours, Class_Participation, Scholarship_num)\n```\n\n## Sorting the data\n\nIf we want to sort the data based on one or more variables, we can use the `arrange()` function, taking the tibble and a variable list as its arguments. By default, `arrange()` sorts in ascending order, but you can specify descending order by using the `desc()` function. For example, to sort the data by `Student_Age` in descending order, and `Weekly_Study_Hours` in ascending order, we can use the following code:\n\n```{r}\nstudent |> \n  arrange(desc(Student_Age), Weekly_Study_Hours)\n```\n\n## Renaming variables\n\nIf we want to rename variables, we can use the `rename()` function with the argument structure `new name = old name`. For example, we can rename the `Student_Age` variable to `age` and the `Weekly_Study_Hours` variable to `weekly_hours`, we can use the following code:\n\n```{r}\nstudent |> \n  rename(age = Student_Age, weekly_hours = Weekly_Study_Hours)\n```\n\n## Categorical variables as factors\n\nIt is often useful to clearly define the levels of a categorical variable, especially if these levels have a meaningful ordering. For unordered categories, R provides the data type `factor`, while for ordered variables the relevant data type is `ordered`. Factor and ordered values appear as character strings when viewed, but are treated as numbers with labels internally, which makes it easier to show descriptives of the variable and include it in models. For example, we can define `High_School_Type` as a factor with three levels and `Attendance` as ordered with the `factor()` and `ordered()` functions. If we don't specify the levels of the factor explicitly, then the levels will be sorted alphabetically.\n\n```{r}\nstudent |> \n  mutate(High_School_Type = factor(High_School_Type),\n         Attendance = ordered(Attendance, levels = c(\"Never\", \"Sometimes\", \"Always\"))) |> \n  select(High_School_Type, Attendance) |> \n  # view variable types and levels by looking at the structure of the data\n  str()\n```\n\n## Data cleaning as a single pipeline\n\nUntil now we didn't save any of our data wrangling steps as new objects, so the original `student1` object is still unchanged. If we want to save the cleaned data as a new object, we can assign the result of the pipe workflow to a new object.\n\n```{r}\nstudent_subset <- student1 |> \n  filter(Student_Age > 21) |> \n  select(Id, Student_Age) |> \n  arrange(desc(Student_Age)) |> \n  rename(age = Student_Age)\n```\n\nTo prepare for the rest of the analysis, let's create a new `data` object that keeps all observations, and converts some of the indicators to numeric and logical, and rename the relevant variables to convenient \"snake case\":\n\n```{r}\ndata <- student |> \n  mutate(scholarship = parse_number(Scholarship),\n         sex = factor(Sex),\n         # testing a logical condition: creates a logical vector\n         additional_work = Additional_Work == \"Yes\",\n         reading = Reading == \"Yes\",\n         notes = Notes == \"Yes\",\n         listening = Listening_in_Class == \"Yes\",\n         # case_when is an expanded if/else case: it allows multiple conditions\n         # the value after the tilde (~) is the value if the condition is TRUE\n         # the function goes through each condition one by one, and stops at the first TRUE one\n         # if no condition is TRUE, the variable value is missing\n         grade = case_when(\n           Grade == \"Fail\" ~ 0,\n           Grade == \"DD\" ~ 1,\n           Grade == \"DC\" ~ 1.5,\n           Grade == \"CC\" ~ 2,\n           Grade == \"CB\" ~ 3,\n           Grade == \"BB\" ~ 3,\n           Grade == \"BA\" ~ 4,\n           Grade == \"AA\" ~ 4\n         )) |> \n  rename(id = Id, age = Student_Age) |> \n  select(id, age, sex, scholarship, additional_work, reading, notes, listening, grade)\n```\n","srcMarkdownNoYaml":"\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, error = FALSE)\n```\n\n# Objectives\n\n## Why R?\n\n-   Free and open-source\n-   Reproducible\n-   Widely used in academia and industry; up-to-date with the latest technological developments\n-   Very versatile: extensive package ecosystem for statistics and more\n-   Powerful data wrangling and visualization capabilities\n-   Extensive community support (open-access books, tutorials, forums, AI tools, etc.)\n\n## Why `tidyverse`?\n\n-   Clean, consistent, intuitive, readable syntax for all steps of the data analysis process\n-   Limited set of functions that can be combined in many ways\n-   Many packages beyond core `tidyverse` with the same underlying design, grammar, and data structures, therefore easier to learn advanced techniques\n\n# Introduction to R\n\n## Objects in R\n\nOne of the most basic types of objects in R is a vector. A vector is a collection of values of the same type, such as numbers, characters, or logicals (TRUE/FALSE). You can create a vector with the `c()` function, which stands for concatenate. If you assign a vector to an object with the assignment operator `<-`, your vector will be saved in your environment so you can work with it within your current R session. Some examples of creating vectors are:\n\n```{r}\nv1 <- c(\"A\", \"B\", \"C\")  # character vector with 3 elements\nv2 <- 25                # numeric vector with 1 element\nv3 <- 1:10              # numeric vector with 10 elements - integers from 1 to 10\n```\n\nTo subset or extract elements from a vector, you can use square brackets `[ ]` with an index. For example, `v1[1]` returns the first element of `v1`, `v3[2:5]` returns the 2nd to 5th elements of `v3`, and `v3[-c(2, 4, 6)]` returns all but the 2nd, 4th and 6th elements of `v3`.\n\n```{r}\nv1[1]\nv3[2:5]\nv3[-c(2, 4, 6)]\n```\n\nA dataframe (or \"tibble\" in `tidyverse`) is a special type of object that combines vectors into a rectangular table. Each column of a dataframe is a vector, and each row is an observation. usually you would load data from an external source, but you can create a dataframe with the `data.frame()` and a tibble with the `tibble()` function. You can also convert other data types such as matrices to tibbles with the `as_tibble()` function. Both functions take vectors as their arguments. Tibbles are preferred because they are more modern and have some convenient features that dataframes don't, but for the most part, differences are minor and for the most part it does not matter whether you work with tibbles or dataframes.\n\nA simple example of creating a tibble is (make sure to load `tidyverse` first):\n\n```{r}\nlibrary(tidyverse)\n\n# define vectors within the tibble() function\ntibble(\n  name = c(\"Alice\", \"Bob\", \"Chris\"),\n  height = c(165, 180, 175)\n)\n\n# define the vectors first, then combine them into a tibble\nname <- c(\"Alice\", \"Bob\", \"Chris\")\nheight <- c(165, 180, 175)\ntibble(name, height)\n```\n\n## Functions in R\n\nFunctions are reusable pieces of code that perform a specific task. They take arguments as inputs and return one or more pieces of output. You will mostly work with functions loaded from various packages or from the base R distribution, and in some cases you may write your own functions to avoid repetition or improve the readability of your code. We will cover writing your own functions later in the program.\n\nAs with vectors, the output of a function is saved to your environment only if you assign the result to an object. For example, `sum(x)` will display the sum of the elements of the vector `x`, but `sum <- sum(x)` will save this result to an object.\n\n```{r}\nx <- c(1, 5, 6, 2, 1, 8)\n\nsum(x)\nsum <- sum(x)\n```\n\nSome important functions on vectors are\n\n```{r}\nmean(x)   # return the mean; add the argument na.rm = TRUE if missing values should be excluded\nlength(x) # give the length of the vector (number of elements)\nunique(x) # list the unique elements of the vector\n```\n\nTo learn more about a function and its arguments, you can use the ? operator or the help() function, for example by typing `?sum` (or equivalently, `?sum()`). It is good practice to request help files from your console and not you R script, since there is no need to save these queries for the future.\n\n# Importing data\n\nR can handle practically any type of data, from simple text files to files used by other (not necessarily open-source) software and complex databases. This gives users a lot of flexibility in terms of data sources and formats.\n\nIn addition to using your own data (e.g. as exported from a survey), the Data Center keeps a continuously updated list of useful datasets by discipline, accessible [here](../../../../tutorials/data).\n\nIn the following, we'll discuss how to import and export from and to various file formats, and discuss a number of available packages to do so.\n\nStart by reading the introduction to importing the most common file types (text files, Excel, SPSS, Stata) [here](../../../../tutorials/r_adv_import). It is good to be aware of the Import dataset button and use it when needed, but in the long run it is easier to be aware of the available import functions and use them directly. The rest of this section gives more information and examples of importing data from different file formats and different levels of tidiness.\n\nWe will use the following packages for importing different file formats:\n\n```{r}\nlibrary(tidyverse)\nlibrary(readxl) # for Excel\nlibrary(haven) # for SPSS, Stata, SAS\n```\n\nIn addition, the `rio` package provides a generic import function, however, it is simply a wrapper for many of the other import functions shown below. While it may be easier to use the same import function for many file formats, `rio` redirects you to the original functions if you look for the possible function arguments, therefore for debugging it is better practice to use the \"original\" functions. In some cases, `rio` can read URL file paths that `readr` and `readxl` can't.\n\nIn the following, we'll work with some example data of student characteristics and grades. First, download [this](https://github.com/ucrdatacenter/projects/raw/refs/heads/main/apprenticeship/2025h1/student_data.zip) zip-file from GitHub, and extract it into a data folder within your apprenticeship project directory. We now import each file, explaining the packages, functions, and function arguments used. These files are all different subsets of the same dataset on student characteristics and grades at a university ([original source](https://www.kaggle.com/datasets/jacksondivakarr/student-classification-dataset?resource=download)).\n\n`student1.csv` is a comma-separated text file. Opening it in a notepad or Excel shows that the column separators are commas (,). The `read_csv()` function from the previous workshop expects commas as a separator, while `read_csv2()` expects semicolons (common with e.g. Dutch language settings). Since CSV files are a form of delimited text files, we can also use the more versatile `read_delim()` function specifying the delimiter as the argument.\n\nIn the following, we use the `read_csv()` (and `read_delim()`) function to import the data, and assign the resulting object to an object called `student1` with the assignment operator `<-`. The `student1` object is now a tibble in the R environment: you can find the object in the Environment tab in RStudio, and view the data by clicking on the object name or running `View(student1)` in the Console.\n\n```{r}\nstudent1 <- read_csv(\"data/student1.csv\")\nstudent1 <- read_delim(\"data/student1.csv\", delim = \",\")\n```\n\nIn this case, we used `read_csv()` only specifying its one mandatory argument: the file path. When using `read_delim()`, we also specified an optional argument: we defined the delimiter as a comma, thereby overriding the default function behavior. To learn more about the mandatory and optional arguments of a function, and find out what the default behaviors are, you can use the `?` operator followed by the function name, e.g. `?read_delim` in the Console to open the help file of a function (or use the search bar of the Help tab).\n\n`student2.tab` is also a delimited text file. Opening it in a notepad shows that the delimiter is a tab. The notation for tab whitespace is `\\t`, which we can specify in the `delim` argument. Like the \".tab\" file extension, \".tsv\" is also a tab-separated text file, so the more specialized `read_tsv()` function also works.\n\nIf you load this data without optional arguments, you'll see that instead of the correct number of columns, we get a single column, with the variable name containing some metadata. To get the correct number of columns, we need to skip the first row of the data that contains this metadata, as the actual data starts from the second row. We can use the `skip` argument to skip the first row. If we use one of the relevant import functions, and assign the outcome to the `student2` object, we can see that the data is now correctly imported and shows up in the environment next to `student1` as another tibble.\n\n```{r}\nstudent2 <- read_delim(\"data/student2.tab\", delim = \"\\t\", skip = 1)\nstudent2 <- read_tsv(\"data/student2.tab\", skip = 1)\n```\n\n`student3.xlsx` is an Excel file. To import Excel file we need the `read_excel()` function from the `readxl` package (the `readxl` package is one of packages that is not a part of core `tidyverse` but uses the same principles). With the `read_excel()` function you can specify which sheet to use in addition to similar arguments as for delimited text files. Notice that by default R imports the \"Metadata\" sheet, so we can use the `sheet` argument to specify which sheet to import. In addition, the first two rows contain introductory text, not the data, so we can use the `skip` argument to skip those rows. You may also notice that previously the variable name for age was `Student_Age` and now it is `Student_age`. You can rename the variable either by giving a full list of column names in the import function, but often it is easier to use the `rename()` function after importing.\n\n```{r}\nstudent3 <- read_excel(\"data/student3.xlsx\", sheet = \"Data\")\n```\n\nThe `haven` package (also not core `tidyverse` but same principles) reads files in the data formats of SPSS (.sav) and Stata (.dta). It can also extract variable and value labels from these files; here we can use the `read_spss()` to import `student4.sav`.\n\n```{r}\nstudent4 <- read_spss(\"data/student4.sav\")\n```\n\nRDS is an R-specific file format that saves all attributes of the dataframe (e.g. grouping, factor levels). It is particularly useful for saving intermediate data files, e.g. saving the cleaned data before analysis to avoid needing to run the data cleaning script repeatedly. To import an RDS file such as `student5.rds`, use the `read_rds()` function.\n\n```{r}\nstudent5 <- read_rds(\"data/student5.rds\")\n```\n\nA few notes regarding importing and exporting data:\n\n-   Always make sure you know your current working directory and the relative path to your data directory. It is better to use relative rather than absolute file paths (i.e. `data/data.csv` instead of `C:/User/Project/data/data.csv`).\n-   Note that if you are using Windows, you may need to replace the backslashes (\\\\) in the file path with forward slashes (/) to avoid errors.\n-   You can import files directly from URLs, although you usually need the URL of a raw file. If a file downloads immediately instead of opening in a raw format, you can try to copy that download link by right-clicking and selecting \"Copy link address\"; the `import()` function from `rio` might be successful with those links.\n-   To export data from R, you can almost always use the `write_...()` function corresponding to the desired file format, e.g. `write_csv()`. For Excel files the preferred export function is `write_xlsx()`, and for SPSS's .sav files it is `write_sav()`.\n-   For other file formats, the generic `write()` function is useful; you can specify any file format, and if your input data is readable in the chosen format, the file will export properly.\n-   In all `write_()` functions you need to specify the data you'd like to save and the output file path (absolute or relative) including chosen file extension.\n\n```{r, eval=FALSE}\n# example export code\nwrite_csv(student1, \"data/new_data.csv\")\n```\n\n# Data wrangling\n\nData wrangling is the process of cleaning, structuring, and enriching raw data into a more usable format. The `dplyr` package is a part of the `tidyverse` and provides a set of functions that can be combined to perform the most common data wrangling tasks. The package is built around the concept of the \"grammar of data manipulation\", which is a consistent set of verbs that can be combined in many ways to achieve the desired result.\n\nThe main functions in `dplyr` are `filter()`, `select()`, `mutate()`, `arrange()`, `group_by()`, `summarize()`, and `rename()`. `dplyr` also provides a set of functions for combining datasets: `bind_rows()` and `bind_cols()` for row-wise and column-wise binding, and `left_join()`, `right_join()`, `inner_join()`, and `full_join()` for joining datasets based on common variables. These functions can be combined using the pipe operator `|>` (or `%>%`, they are mostly equivalent) to create a data wrangling workflow. The pipe operator takes the output of the function on its left and passes it as the first argument to the function on its right. This allows you to chain multiple functions together in a single line of code, making your code more readable and easier to understand.\n\nIn the following, we'll work with the `student` datasets imported in the previous section and show how to use the main `dplyr` functions to clean the data so it is suitable for analysis. These steps are useful even if the input data is quite clean, as we often need to work with only a subset of observations/variables, define new variables, or aggregate the data.\n\n## Merging datasets\n\nIn our current application, we have five datasets that contain different observations of the same, larger dataset. So we can list all datasets in a row-binding function to combine them into a single dataset called `student`.\n\n```{r}\nstudent <- bind_rows(student1, student2, student3, student4, student5)\n```\n\nIn the following, we'll demonstrate the key data cleaning functions on this merged tibble.\n\n## Filtering observations\n\nIf we want to keep only a subset of observations, we can use the `filter()` function. We can specify a logical condition as the argument to `filter()`, and only observations that meet that condition will be kept. For example, to keep only students who are over 21 years old, we can use the following code:\n\n```{r}\nfilter(student, Student_Age > 21)\n```\n\nIn a pipe workflow, the same code would look like this:\n\n```{r}\nstudent |> \n  filter(Student_Age > 21)\n```\n\nWe can also apply logical conditions to character variables, e.g. to keep only students who went to a private high school and who did not receive a failing grade. Filters can be combined with AND (`,` or `&`) and OR (`|`) operators into a single function. Note the use of quotation marks around the character values in the logical condition and the double equal sign `==` to denote equality.\n\n```{r}\nstudent |> \n  filter(High_School_Type == \"Private\", Grade != \"Fail\") \n```\n\nAnother useful logical operator is `%in%`, which allows you to filter observations based on a list of values. For example, to keep only students who receive either 75% or 100% scholarships, we can use the following code:\n\n```{r}\nstudent |> \n  filter(Scholarship %in% c(\"75%\", \"100%\"))\n```\n\n## Selecting variables\n\nIf we want to keep only a subset of variables, we can use the `select()` function. We can specify the variables we want to keep (or exclude, with `-` signs) as the arguments to `select()`, and only those variables will be kept. For example, to keep only the `Id` and `Student_Age` variables, we can use the following code:\n\n```{r}\nselect(student, Id, Student_Age)\n```\n\nWe can also select columns based on their location in the dataframe or by looking for patterns in the column names:\n\n```{r}\nselect(student, 1:3) # select the first three columns\nselect(student, starts_with(\"Student\")) # select columns that start with \"Student\"\nselect(student, -Grade) # keep everything but \"Grade\"\nselect(student, -c(2, 6, 10)) # keep everything but the 2nd, 6th, and 10th columns\n```\n\nA pipe workflow allows us to combine the filtering and selecting operations into a single, step-by-step workflow:\n\n```{r}\nstudent |> \n  filter(Student_Age > 21) |> \n  select(Id, Student_Age)\n```\n\n## Creating new variables\n\nIf we want to create a new variable based on existing variables, we can use the `mutate()` function. We can specify the new variable name and the calculation for the new variable as the arguments to `mutate()`, and the new variable will be added to the dataset. For example, we can create a new variable `Daily_Study_Hours` that divides `Weekly_Study_Hours` by 5, a new variable `Class_Participation` that is a logical variable indicating whether the student has at least one \"Yes\" answer for reading, listening, and taking notes, and a new variable `Scholarship_num` that extracts the numeric value of `Scholarship` if the string contains a number.\n\n```{r}\nstudent |> \n  # create new variables\n  mutate(Daily_Study_Hours = Weekly_Study_Hours / 5,\n         Class_Participation = Reading == \"Yes\" | Listening_in_Class == \"Yes\" | Notes == \"Yes\",\n         Scholarship_num = parse_number(Scholarship)) |> \n  # show only ID and the new variables\n  select(Id, Daily_Study_Hours, Class_Participation, Scholarship_num)\n```\n\n## Sorting the data\n\nIf we want to sort the data based on one or more variables, we can use the `arrange()` function, taking the tibble and a variable list as its arguments. By default, `arrange()` sorts in ascending order, but you can specify descending order by using the `desc()` function. For example, to sort the data by `Student_Age` in descending order, and `Weekly_Study_Hours` in ascending order, we can use the following code:\n\n```{r}\nstudent |> \n  arrange(desc(Student_Age), Weekly_Study_Hours)\n```\n\n## Renaming variables\n\nIf we want to rename variables, we can use the `rename()` function with the argument structure `new name = old name`. For example, we can rename the `Student_Age` variable to `age` and the `Weekly_Study_Hours` variable to `weekly_hours`, we can use the following code:\n\n```{r}\nstudent |> \n  rename(age = Student_Age, weekly_hours = Weekly_Study_Hours)\n```\n\n## Categorical variables as factors\n\nIt is often useful to clearly define the levels of a categorical variable, especially if these levels have a meaningful ordering. For unordered categories, R provides the data type `factor`, while for ordered variables the relevant data type is `ordered`. Factor and ordered values appear as character strings when viewed, but are treated as numbers with labels internally, which makes it easier to show descriptives of the variable and include it in models. For example, we can define `High_School_Type` as a factor with three levels and `Attendance` as ordered with the `factor()` and `ordered()` functions. If we don't specify the levels of the factor explicitly, then the levels will be sorted alphabetically.\n\n```{r}\nstudent |> \n  mutate(High_School_Type = factor(High_School_Type),\n         Attendance = ordered(Attendance, levels = c(\"Never\", \"Sometimes\", \"Always\"))) |> \n  select(High_School_Type, Attendance) |> \n  # view variable types and levels by looking at the structure of the data\n  str()\n```\n\n## Data cleaning as a single pipeline\n\nUntil now we didn't save any of our data wrangling steps as new objects, so the original `student1` object is still unchanged. If we want to save the cleaned data as a new object, we can assign the result of the pipe workflow to a new object.\n\n```{r}\nstudent_subset <- student1 |> \n  filter(Student_Age > 21) |> \n  select(Id, Student_Age) |> \n  arrange(desc(Student_Age)) |> \n  rename(age = Student_Age)\n```\n\nTo prepare for the rest of the analysis, let's create a new `data` object that keeps all observations, and converts some of the indicators to numeric and logical, and rename the relevant variables to convenient \"snake case\":\n\n```{r}\ndata <- student |> \n  mutate(scholarship = parse_number(Scholarship),\n         sex = factor(Sex),\n         # testing a logical condition: creates a logical vector\n         additional_work = Additional_Work == \"Yes\",\n         reading = Reading == \"Yes\",\n         notes = Notes == \"Yes\",\n         listening = Listening_in_Class == \"Yes\",\n         # case_when is an expanded if/else case: it allows multiple conditions\n         # the value after the tilde (~) is the value if the condition is TRUE\n         # the function goes through each condition one by one, and stops at the first TRUE one\n         # if no condition is TRUE, the variable value is missing\n         grade = case_when(\n           Grade == \"Fail\" ~ 0,\n           Grade == \"DD\" ~ 1,\n           Grade == \"DC\" ~ 1.5,\n           Grade == \"CC\" ~ 2,\n           Grade == \"CB\" ~ 3,\n           Grade == \"BB\" ~ 3,\n           Grade == \"BA\" ~ 4,\n           Grade == \"AA\" ~ 4\n         )) |> \n  rename(id = Id, age = Student_Age) |> \n  select(id, age, sex, scholarship, additional_work, reading, notes, listening, grade)\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"wrangling.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.555","editor":"visual","theme":"simplex","mainfont":"Cormorant SC","fontsize":"20px","title":"Data Center Apprenticeship: Introduction to data wrangling in R","subtitle":"January 2025","date":"Last updated: `r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}